[
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/3.1-public-instance/",
	"title": "Connect to Public Instance",
	"tags": [],
	"description": "",
	"content": "\nGo to EC2 service management console. Click on Public Linux Instance. Click Actions. Click Security. Click Modify IAM role. At the Modify IAM role page. Click to select SSM-Role. Click Save. You will need to wait about 10 minutes before performing the next step. This time our EC2 instance will automatically register with the Session Manager.\nGo to the AWS Systems Manager service management console Drag the left menu slider down. Click Session Manager. Click Start Session. Then select Public Linux Instance and click Start session to access the instance. Terminal will appear on the browser. Testing with the command sudo tcpdump -nn port 22 and sudo tcpdump we will see no SSH traffic but only HTTPS traffic. Above, we have created a connection to the public instance without opening SSH port 22, for better security, avoiding any attack to the SSH port.\nOne disadvantage of the above method is that we have to open the Security Group outbound at port 443 to the internet. Since it\u0026rsquo;s a public instance, it probably won\u0026rsquo;t be a problem, but if you want extra security, you can block port 443 to the internet and still use the Session Manager. We will go through this in the private instance section below.\nYou can click terminate to end the currently connected session before proceeding to the next step.\n"
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/3.2-private-instance/3.2.2-createvpcendpoint/3.2.2.1-endpointssm/",
	"title": "Create Endpoint ssm",
	"tags": [],
	"description": "",
	"content": "Create VPC Endpoint SSM Go to VPC service management console Click Endpoints. Click Create endpoint. At the Create endpoint page. In the Name tag field, enter SSM. In the Service Category section, select AWS Services. In the Service Name section, In the Service category section, select: AWS services In the Service Name section enter: SSM then select Service Name: com.amazonaws.ap-southeast-1.ssm. In the Service Name column, click com.amazonaws.ap-southeast-1.ssm. In the VPC section, select Lab VPC. Select the first AZ, then select the Lab Private Subnet subnet. Scroll down. In the Security Group section, select the Security group SG VPC Endpoint that we created earlier. In the Policy section, select Full access. Scroll down. Click Create endpoint. We have created the VPC Interface Endpoint for SSM. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-createec2/2.1.1-createvpc/",
	"title": "Create VPC",
	"tags": [],
	"description": "",
	"content": "Create VPC Lab VPC Go to VPC service management console Click Your VPC. Click Create VPC. At the Create VPC page. In the Name tag field, enter Lab VPC. In the IPv4 CIDR field, enter: 10.10.0.0/16. Click Create VPC. "
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/3.2-private-instance/3.2.1-enablevpcdns/",
	"title": "Enable DNS hostnames",
	"tags": [],
	"description": "",
	"content": "Enable DNS hostnames on VPC. To create VPC Endpoint we will need to enable DNS hostnames feature on VPC. Go to VPC service management console\nClick Your VPCs.\nSelect Lab VPC.\nClick Actions.\nClick Edit DNS hostnames.\nClick Endpoint, then click Create Endpoint.\nAt the Edit DNS hostnames page. Click to select Enable. Click Save changes. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-createec2/",
	"title": "Preparing VPC and EC2",
	"tags": [],
	"description": "",
	"content": "In this step, we will need to create a VPC with 2 public / private subnets. Then create 1 EC2 Instance Linux located in the public subnet, 1 EC2 Instance Windows located in the private subnet.\nThe architecture overview after you complete this step will be as follows:\nTo learn how to create EC2 instances and VPCs with public/private subnets, you can refer to the lab:\nAbout Amazon EC2 Works with Amazon VPC Content Create VPC Create Public Subnet Create Private Subnet Create security group Create public Linux server Create private Windows server "
},
{
	"uri": "//localhost:1313/",
	"title": "Session Management",
	"tags": [],
	"description": "",
	"content": "\rINTERNSHIP REPORT Student Information Full Name: Lương Nguyễn Duy Khang\nPhone Number: 0931984914\nEmail: lndkhang278@gmail.com\nUniversity: FPT University\nMajor: Software Engineer\nClass:\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 12/08/2025 to 12/11/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback Content Introduction Preparation Connect to EC2 instance Manage session logs Port Forwarding Clean up resources "
},
{
	"uri": "//localhost:1313/4-s3log/4.1-updateiamrole/",
	"title": "Update IAM Role",
	"tags": [],
	"description": "",
	"content": "For our EC2 instances to be able to send session logs to the S3 bucket, we will need to update the IAM Role assigned to the EC2 instance by adding a policy that allows access to S3.\nUpdate IAM Role Go to IAM service management console Click Roles. In the search box, enter SSM. Click on the SSM-Role role. Click Attach policies. In the Search box enter S3. Click the policy AmazonS3FullAccess. Click Attach policy. In the production environment, we will grant stricter permissions to the specified S3 bucket. In the framework of this lab, we use the policy AmazonS3FullAccess for convenience.\nNext, we will proceed to create an S3 bucket to store session logs.\n"
},
{
	"uri": "//localhost:1313/1-introduce/week1/",
	"title": "WEEK 1",
	"tags": [],
	"description": "",
	"content": "WORKLOG Week 1 objectives: Connected and formed groups with students at FCJ Proposed ideas about final project Studied and did labs on FCJ websites Understood basic concepts of cloud and AWS services Task carried out this week Day Task Start Date Completion Date Reference Material 2 - Get used to and take notes of First Cloud Journey tasks for students, its rules and learning materials 09/08/2025 09/08/2025 3 - Self study about cloud - Explore AWS services 09/09/2025 09/09/2025 Link 4 - Create AWS Free Tier account - Learn how to manage cost with AWS Budgets Do: + Create AWS account + Create different types of budgets 09/10/2025 09/10/2025 Link 5 - Study about EC2 - SSH connection methods to EC2 - Learn about Elastic IP - Propose ideas about final project - Study about VPC 09/11/2025 09/11/2025 Link 6 Do: + Create security groups + Create subnets + Launch an EC2 instance + Connect via SSH + Attach an EBS volume - Join a meeting and choose one idea for final project 09/12/2025 09/12/2025 Link Week 1 Achievements Understood what AWS is and learned the basic service groups:\nCompute Storage Networking Database Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region Explored AWS services through self-study and documentation to understand their usage.\nLearned how to manage costs effectively with AWS Budgets, including creating different types of budgets.\nGained hands-on experience with EC2 by studying its features, connection methods (SSH), and Elastic IP.\nLearned the basics of VPC and networking setup in AWS.\nPracticed creating security groups, subnets, and launching an EC2 instance.\nSuccessfully connected to an EC2 instance via SSH and attached an EBS volume.\nWorked collaboratively to propose and select one idea for the final project.\n"
},
{
	"uri": "//localhost:1313/1-introduce/week2/",
	"title": "WEEK 2",
	"tags": [],
	"description": "",
	"content": "WORKLOG Week 2 Objectives Learn and practice AWS storage and database services (Amazon S3, Amazon RDS). Get familiar with and self-study Spring Boot to prepare for backend development. Gain knowledge of system monitoring with Amazon CloudWatch. Learn and practice deployment with Amazon Lightsail and Lightsail Container. Continue self-studying PostgreSQL to integrate with Spring Boot. Explore resource scaling with Amazon EC2 Auto Scaling. Tasks Carried Out This Week Day Task Start Date Completion Date Reference Material 2 - Study Amazon S3 and Amazon RDS\n- Do: Amazon S3 labs, Amazon RDS labs\n- Self-study Spring Boot 09/15/2025 09/15/2025 AWS Study Group 3 - Self-study Spring Boot\n- Study Amazon CloudWatch 09/16/2025 09/16/2025 AWS Study Group 4 - Self-study Spring Boot and PostgreSQL\n- Do: Amazon CloudWatch labs 09/17/2025 09/17/2025 AWS Study Group 5 - Self-study Spring Boot and PostgreSQL\n- Study Amazon Lightsail and Lightsail Container\n- Do: Lightsail labs, Lightsail Container labs 09/18/2025 09/18/2025 AWS Study Group 6 - Self-study Spring Boot and PostgreSQL\n- Study Amazon EC2 Auto Scaling 09/19/2025 09/19/2025 AWS Study Group Week 2 Achievements Completed Amazon S3 labs and learned bucket creation, upload/download, and access management. Completed Amazon RDS labs, created databases, connected, and managed data. Self-studied and understood the basics of Spring Boot (project structure, dependencies, basic API creation). Learned about Amazon CloudWatch and practiced labs for monitoring, metrics, and alarms. Learned PostgreSQL and understood basic integration with Spring Boot. Completed Amazon Lightsail and Lightsail Container labs, deployed sample apps, and managed containers. Understood Amazon EC2 Auto Scaling mechanism and how instances scale automatically based on demand. "
},
{
	"uri": "//localhost:1313/1-introduce/week3/",
	"title": "WEEK 3",
	"tags": [],
	"description": "",
	"content": "WORKLOG Week 3 Objectives Set up the base project for backend development. Learn and practice Amazon Route 53. Continue learning about Amazon EC2 Auto Scaling. Develop core authentication features: register, login, and JWT services. Study and practice with Amazon CLI. Collaborate with the team to review project progress. Tasks Carried Out This Week Day Task Start Date Completion Date Reference Material 2 - Set up base project for development\n- Study about Amazon Route 53\n- Do: Amazon EC2 Auto Scaling labs 09/22/2025 09/22/2025 AWS Study Group 3 - Start developing register feature\n- Do: Amazon Route 53 labs 09/23/2025 09/23/2025 AWS Study Group 4 - Continue developing register feature\n- Study about Amazon CLI 09/24/2025 09/24/2025 AWS Study Group 5 - Team meeting about project progress\n- Complete register and start developing login feature and JWT services 09/25/2025 09/25/2025 AWS Study Group 6 - Finish login and JWT services\n- Do: Amazon CLI labs 09/26/2025 09/26/2025 AWS Study Group Week 3 Achievements Successfully set up the base project structure for development. Completed labs on Amazon EC2 Auto Scaling and Amazon Route 53, gaining knowledge in scaling and DNS management. Implemented user registration feature and later expanded with login and JWT-based authentication. Practiced using Amazon CLI and completed related labs. Held a team meeting to discuss project progress and align development tasks. Completed core authentication flow (register + login + JWT services), providing a foundation for secure backend development. "
},
{
	"uri": "//localhost:1313/1-introduce/week4/",
	"title": "WEEK 4",
	"tags": [],
	"description": "",
	"content": "WORKLOG Week 4 Objectives Fix and optimize existing authentication features (register/login). Learn and integrate MoMo payment gateway into the project. Participate in team meetings to review progress and discuss project proposal. Study and practice with Amazon DynamoDB. Learn how to use Cloudinary for image uploads in Spring Boot. Complete labs on Amazon DynamoDB and integrate Cloudinary into the project. Tasks Carried Out This Week Day Task Start Date Completion Date Reference Material 2 - Fix bugs in register/login services\n- Study about MoMo services and how to integrate in Spring Boot 09/29/2025 09/29/2025 AWS Study Group 3 - Team meeting about project progress\n- Develop and integrate MoMo payment in project 09/30/2025 09/30/2025 4 - Team meeting to discuss project proposal and assign different tasks for members\n- Finish MoMo payment integration 10/01/2025 10/01/2025 5 - Study about DynamoDB\n- Learn about Cloudinary and how to implement it for image uploads in Spring Boot 10/02/2025 10/02/2025 AWS Study Group 6 - Do labs about DynamoDB\n- Integrate Cloudinary in the project 10/03/2025 10/03/2025 AWS Study Group Week 4 Achievements Fixed and improved register/login services for better stability. Successfully learned and integrated MoMo payment gateway into the backend project. Participated in team meetings to review progress and coordinate new development tasks. Gained hands-on experience with Amazon DynamoDB through labs and practice. Learned how to use Cloudinary for efficient image storage and integrated it into the project. Strengthened overall backend functionality with payment and media upload features, preparing the system for future expansion. "
},
{
	"uri": "//localhost:1313/1-introduce/week5/",
	"title": "WEEK 5",
	"tags": [],
	"description": "",
	"content": "WORKLOG Week 5 Objectives Learn and practice Amazon ElastiCache to improve application performance through caching. Study and implement Google OAuth 2 for multi-login authentication options. Research and understand Amazon CloudFront and its use for content delivery and website acceleration. Complete labs for ElastiCache and CloudFront to gain practical experience. Study Edge Computing concepts with Amazon CloudFront and Lambda@Edge. Research and integrate MoMo IPN (Instant Payment Notification) to verify payment status. Learn and practice integrating Amazon S3 for file storage, upload, and download management. Tasks Carried Out This Week Day Task Start Date Completion Date Reference Material 2 - Study about Amazon ElastiCache\n- Learn about Google OAuth 2 to integrate multiple login options in the project 10/06/2025 10/06/2025 AWS Study Group 3 - Study and research about Amazon CloudFront\n- Develop and integrate OAuth 2 into the project 10/07/2025 10/07/2025 AWS Study Group 4 - Do labs about Amazon ElastiCache and Amazon CloudFront\n- Finish integrating OAuth 2 10/08/2025 10/08/2025 AWS Study Group 5 - Study about Edge Computing with Amazon CloudFront and Lambda@Edge\n- Research about MoMo IPN to verify paid status 10/09/2025 10/09/2025 AWS Study Group 6 - Integrate MoMo IPN into project\n- Learn about integrating Amazon S3 to store, upload, and download files 10/10/2025 10/10/2025 AWS Study Group Week 5 Achievements Gained understanding of Amazon ElastiCache and its benefits for caching and performance optimization. Successfully implemented Google OAuth 2 for multiple login options, enhancing authentication flexibility. Completed labs and research on Amazon CloudFront, learning about CDN setup and content distribution. Practiced Edge Computing using Lambda@Edge to handle requests closer to users for lower latency. Integrated MoMo IPN into the project to automatically verify and confirm successful transactions. Learned and applied Amazon S3 integration for secure file storage, upload, and download functionality. Improved project scalability, authentication, and reliability through practical use of multiple AWS services. "
},
{
	"uri": "//localhost:1313/1-introduce/week6/",
	"title": "WEEK 6",
	"tags": [],
	"description": "",
	"content": "WEEK 6 WORKLOG Week 6 Objectives Integrate Amazon S3 into the project to support image upload and download functionality. Complete AWS CloudFront and Lambda@Edge labs to strengthen content delivery knowledge. Study Windows Workloads on AWS and Directory Services using AWS Managed Microsoft AD. Research and evaluate third-party APIs for calculating shipping fees, particularly Giao Hang Tiet Kiem (GHTK). Begin integrating the GHTK API into the existing project. Reinforce understanding of Secure Architectures in preparation for the midterm exam. Explore AWS VM Import/Export for virtual machine migration concepts. Task Carried Out This Week Day Task Start Date Completion Date Reference Material 2 - Integrating S3 to the project with upload and download functions for images - Do labs related to Amazon CloudFront and Lambda@Edge 10/13/2025 10/13/2025 AWS Study Group 3 - Study about Windows Workloads on AWS and Directory Services with AWS Managed Microsoft AD - Considering and evaluating services to use to calculate shipping fee in the project 10/14/2025 10/14/2025 AWS Study Group 4 - Finish labs related to Windows Workloads on AWS and Directory Services with AWS Managed Microsoft AD - Research and study about Giao Hang Tiet Kiem API to calculate shipping fee 10/15/2025 10/15/2025 AWS Study Group GHTK API Docs 5 - Start to integrate Giao Hang Tiet Kiem API into the project - Do labs about Building Highly Available Web Applications - Join meeting about topic of Reinventing DevSecOps 10/16/2025 10/16/2025 AWS Study Group 6 - Revise knowledge about Secure Architecture to prepare for midterm exam - Continue to integrate Giao Hang Tiet Kiem API - Read about topic VM Migration with AWS VM Import/Export 10/17/2025 10/17/2025 AWS Study Group Week 6 Achievements Successfully integrated Amazon S3 into the project, enabling image upload and download features. Completed practical labs on AWS CloudFront and Lambda@Edge, gaining insights into edge computing and CDN optimization. Studied and finished labs on Windows Workloads and AWS Managed Microsoft AD, understanding how to manage hybrid environments. Researched and tested the GHTK shipping fee API, beginning integration into the project using Spring Boot. Participated in a team meeting about “Reinventing DevSecOps,” discussing security integration in CI/CD pipelines. Reviewed Secure Architecture principles, including IAM, encryption, and WAF, for midterm preparation. Read and summarized key points about VM migration using AWS VM Import/Export tools. "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": " Week 1: Getting familiar with AWS and basic AWS services. Week 2: Learning core AWS services (S3, RDS, CloudWatch, Lightsail, EC2 Auto Scaling) and practicing backend setup with Spring Boot and PostgreSQL. Week 3: Setting up the backend project, implementing authentication (register, login, JWT), and practicing with Route 53, EC2 Auto Scaling, and AWS CLI. Week 4: Improving backend authentication and integrating MoMo payment and Cloudinary while practicing core AWS services. Week 5: Exploring advanced AWS services and integrating OAuth 2, MoMo IPN, and Amazon S3 into the project. Week 6: Doing task E… Week 7: Doing task G… Week 8: Doing task H… Week 9: Doing task I… Week 10: Doing task L… Week 11: Doing task M… Week 12: Doing task N… "
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/3.2-private-instance/",
	"title": "Connect to Private instance",
	"tags": [],
	"description": "",
	"content": "For Windows instance located in private subnet, there is no public IP, no internet gateway so it cannot go out internet.\nWith this type of instance, the traditional way is to use Bastion host technique which is expensive and laborious, but here we will use Session Manager with this type.\nBasically, the private instance still has to open the TCP 443 port to System Manager, but we don\u0026rsquo;t want to allow connection go out to the internet, but only in its VPC, to enhance our security posture.\nTo do that, we have to include the System Manager endpoint in the VPC, that is, using the VPC interface endpoint:\nVPC interface endpoint is attached to the subnet, so this method can be done not only with private subnet but also with public subnet, meaning that with public subnet, you can completely prohibit TCP 443 go out to the internet.\nContent: Enable DNS hostnames Create VPC Endpoint Connect Private Instance "
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/3.2-private-instance/3.2.2-createvpcendpoint/3.2.2.2-endpointssmmessages/",
	"title": "Create Endpoint ssmmessages",
	"tags": [],
	"description": "",
	"content": "Create VPC Endpoint SSMMESSAGES Go to VPC service management console Click Endpoints. Click Create endpoint. At the Create endpoint page. In the Name tag field, enter SSMMESSAGES. In the Service Category section, select AWS Services. In the Service Name section, In the Service category select: AWS services In the Service Name field enter: ssmmessages then select Service Name: com.amazonaws.ap-southeast-1.ssmmessages. In the Service Name column, click com.amazonaws.ap-southeast-1.ssmmessages. In the VPC section, select Lab VPC. Select the first AZ, then select the Lab Private Subnet subnet. Scroll down. In the Security Group section, select the Security group SG VPC Endpoint that we created earlier. In the Policy section, select Full access Scroll down. Click Create endpoint. We have created the VPC Interface Endpoint SSMMESSAGES. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.2-createiamrole/",
	"title": "Create IAM Role",
	"tags": [],
	"description": "",
	"content": "Create IAM Role In this step, we will proceed to create IAM Role. In this IAM Role, the policy AmazonSSMManagedInstanceCore will be assigned, this is the policy that allows the EC2 server to communicate with the Session Manager.\nGo to IAM service administration interface In the left navigation bar, click Roles. Click Create role. Click AWS service and click EC2. Click Next: Permissions. In the Search box, enter AmazonSSMManagedInstanceCore and press Enter to search for this policy. Click the policy AmazonSSMManagedInstanceCore. Click Next: Tags. Click Next: Review. Name the Role SSM-Role in Role Name Click Create Role . Next, we will make the connection to the EC2 servers we created with Session Manager.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-createec2/2.1.2-createpublicsubnet/",
	"title": "Create Public Subnet",
	"tags": [],
	"description": "",
	"content": "Create Public Subnet Click Subnets. Click Create subnet. At the Create subnet page. In the VPC ID section, click Lab VPC. In the Subnet name field, enter Lab Public Subnet. In the Availability Zone section, select the first Availability zone. In the field IPv4 CIRD block enter 10.10.1.0/24. Scroll to the bottom of the page, click Create subnet.\nClick Lab Public Subnet.\nClick Actions. Click Edit subnet settings. Click Enable auto-assign public IPv4 address. Click Save. Click Internet Gateways. Click Create internet gateway. At the Create internet gateway page. In the Name tag field, enter Lab IGW. Click Create internet gateway. After successful creation, click Actions. Click Attach to VPC. At the Attach to VPC page. In the Available VPCs section, select Lab VPC. Click Attach internet gateway. Check the successful attaching process as shown below. Next we will create a custom route table to assign to Lab Public Subnet. Click Route Tables. Click Create route table. At the Create route table page. In the Name field, enter Lab Publicrtb. In the VPC section, select Lab VPC. Click Create route table. After creating the route table successfully. Click Edit routes. At the Edit routes page. Click Add route. In the Destination field, enter 0.0.0.0/0 In the Target section, select Internet Gateway and then select Lab IGW. Click Save changes. Click the Subnet associations tab. Click Edit subnet associations to proceed with the associate custom route table we just created in Lab Public Subnet. At the Edit subnet associations page. Click on Lab Public Subnet. Click Save associations. Check that the route table information has been associated with Lab Public Subnet and the internet route information has been pointed to the Internet Gateway as shown below. "
},
{
	"uri": "//localhost:1313/4-s3log/4.2-creates3bucket/",
	"title": "Create S3 Bucket",
	"tags": [],
	"description": "",
	"content": "In this step, we will create an S3 bucket to store session logs sent from EC2 instances.\nCreate S3 Bucket Access S3 service management console Click Create bucket. At the Create bucket page. In the Bucket name field, enter the bucket name lab-yourname-bucket-0001 In the Region section, select Region you are doing the current lab. The name of the S3 bucket must not be the same as all other S3 buckets in the system. You can substitute your name and enter a random number when generating the S3 bucket name.\nScroll down and click Create bucket. When we created the S3 bucket we did Block all public access so our EC2 instances won\u0026rsquo;t be able to connect to S3 via the internet. In the next step, we will configure the S3 Gateway Endpoint feature to allow EC2 instances to connect to the S3 bucket via the VPC\u0026rsquo;s internal network.\n"
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/3.2-private-instance/3.2.2-createvpcendpoint/",
	"title": "Create VPC Endpoint",
	"tags": [],
	"description": "",
	"content": "Create VPC Endpoint SSM We will create 3 interface endpoints required by the Session Manager:\nInterface endpoints: com.amazonaws.region.ssm com.amazonaws.region.ec2messages com.amazonaws.region.ssmmessages You can refer to more here\nContent: Create Endpoint ssm Create Endpoint ssmmessages Create Endpoint ec2messages "
},
{
	"uri": "//localhost:1313/2-prerequiste/",
	"title": "Proposal ",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/3.2-private-instance/3.2.3-connectec2/",
	"title": "Connect to instance",
	"tags": [],
	"description": "",
	"content": "Assign IAM role and restart EC2 instance. Go to EC2 service management console Click Private Windows Instance. Click Actions. Click Security. Click Modify IAM Role. At the Modify IAM Role page. In the IAM role section, select SSM-Role. Click Save. Click Private Windows Instance. Click Instance state. Click Reboot instance to restart, then click Reboot to confirm. Please wait 5 minutes before doing the next step.\nConnect to the private EC2 instance. Go to System Manager - Session Manager service management console Click Start session. Click Private Windows Instance. Click Start session. Type ipconfig command to check the IP address information of Private Windows Instance as shown below. "
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/3.2-private-instance/3.2.2-createvpcendpoint/3.2.2.3-endpointec2messages/",
	"title": "Create Endpoint ec2messages",
	"tags": [],
	"description": "",
	"content": "Create VPC Endpoint EC2MESSAGES Go to VPC service management console Click Endpoints. Click Create endpoint. At the Create endpoint page. In the Name tag field, enter SSMMESSAGES. In the Service Category section, select AWS Services. In the Service Name section, In the Service category select: AWS services In the field Service Name enter: ec2 then select Service Name: com.amazonaws.ap-southeast-1.ec2messages. In the Service Name column, click com.amazonaws.ap-southeast-1.ec2messages. In the VPC section, select Lab VPC. Select the first AZ, then select the Lab Private Subnet subnet. Scroll down. In the Security Group section, select the Security group SG VPC Endpoint that we created earlier. In the Policy section, select Full access Scroll down. Click Create endpoint. We have created the VPC Interface Endpoint EC2MESSAGES.\nMake sure the 3 required endpoints have been created as shown below.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-createec2/2.1.3-createprivatesubnet/",
	"title": "Create Private Subnet",
	"tags": [],
	"description": "",
	"content": "Create Private Subnet Click Subnets. Click Create subnet. At the Create subnet page. In the VPC ID section, click Lab VPC. In the Subnet name field, enter Lab Private Subnet. In the Availability Zone section, select the first Availability zone. In the field IPv4 CIRD block enter 10.10.2.0/24. Scroll to the bottom of the page, click Create subnet. The next step is to create the necessary security groups for the lab.\n"
},
{
	"uri": "//localhost:1313/4-s3log/4.3-creategwes3/",
	"title": "Create S3 Gateway endpoint",
	"tags": [],
	"description": "",
	"content": " Go to VPC service management console Click Endpoints. Click Create endpoint. At the Create endpoint page. In the Name tag field, enter S3GW. In the Service Category section, click AWS services. In the search box enter S3, then select com.amazonaws.[region].s3 In the Services section, select com.amazonaws.[region].s3 with the Type of Gateway. In the VPC section, select Lab VPC. In the Route tables section, select both route tables. Scroll down, click Create endpoint. The next step is to configure Session Manager to store session logs to the S3 bucket we created.\n"
},
{
	"uri": "//localhost:1313/3-accessibilitytoinstances/",
	"title": "Translated blogs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-createec2/2.1.4-createsecgroup/",
	"title": "Create security groups",
	"tags": [],
	"description": "",
	"content": "Create security groups In this step, we will proceed to create the security groups used for our instances. As you can see, these security groups will not need to open traditional ports to ssh like port 22 or remote desktop through port 3389.\nCreate security group for Linux instance located in public subnet Go to VPC service management console Click Security Group. Click Create security group. In the Security group name field, enter SG Public Linux Instance. In the Description section, enter SG Public Linux Instance. In the VPC section, click the X to reselect the Lab VPC you created for this lab. Keep Outbound rule, drag the mouse to the bottom. Click Create security group. As you can see, the security group we created to use for Linux public instances will not need to open traditional ports to ssh like port 22.\nCreate a security group for a Windows instance located in a private subnet After successfully creating a security group for the Linux instance located in the public subnet, click the Security Groups link to return to the Security groups list. Click Create security group.\nIn the Security group name field, enter SG Private Windows Instance.\nIn the Description section, enter SG Private Windows Instance. In the VPC section, click the X to reselect the Lab VPC you created for this lab. Scroll down. Add Outbound rule to allow TCP 443 connection to 10.10.0.0/16 ( CIDR of Lab VPC we created) Click Create security group. For the Instance in the private subnet, we will connect to the Session Manager endpoint over a TLS encrypted connection, so we need to allow outbound connection from our instance to VPC CIDR through port 443.\nCreate security group for VPC Endpoint In this step, we will create security group for VPC Endpoint of Session Manager. After successfully creating the security group for the Windows instance in the private subnet, click the Security Groups link to return to the Security groups list. Click Create security group. In the Security group name field, enter SG VPC Endpoint. In the Description section, enter SG VPC Endpoint. In the VPC section, click the X to reselect the Lab VPC you created for this lab. Scroll down. Delete Outbound rule. Add Inbound rule allowing TCP 443 to come from 10.10.0.0/16 ( CIDR of Lab VPC we created ). Click Create security group. So we are done creating the necessary security groups for EC2 instances and VPC Endpoints.\n"
},
{
	"uri": "//localhost:1313/4-s3log/",
	"title": "Events participated",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/4-s3log/4.4-configsessionlogs/",
	"title": "Monitor session logs",
	"tags": [],
	"description": "",
	"content": "Monitor session logs Access System Manager - Session Manager service management console Click the Preferences tab. Click Edit. Scroll down, at S3 logging, click Enable. Uncheck Allow only encrypted S3 buckets. Click Choose a bucket name from the list. Select the S3 bucket you created. Scroll down, click Save to save the configuration.\nAccess System Manager - Session Manager service management console\nClick Start session. Click Private Windows Instance. Click Start session. Type the command ipconfig. Type the command hostname. Click Terminate to exit the session, click Terminate again to confirm. Check Session logs in S3 Go to S3 service management console Click on the name of the S3 bucket we created for the lab. Click on the object name sessions log On the objects detail page, click Open. Object logs will be opened in a new tab in the browser. You can view the stored commands in session logs. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-createec2/2.1.5-createec2linux/",
	"title": "Create Public instance",
	"tags": [],
	"description": "",
	"content": " Go to EC2 service management console Click Instances. Click Launch instances. On the Step 1: Choose an Amazon Machine Image (AMI) page. Click Select to select AMI Amazon Linux 2 AMI. On the Step 2: Choose an Instance Type page. Click on Instance type t2.micro. Click Next: Configure Instance Details. At Step 3: Configure Instance Details page In the Network section, select Lab VPC. In the Subnet section, select Lab Public Subnet. In the Auto-assign Public IP section, select Use subnet setting (Enable) Click Next: Add Storage. Click Next: Add Tags to move to the next step. Click Next: Configure Security Group to move to the next step. On page Step 6: Configure Security Group. Select Select an existing security group. Select security group SG Public Linux Instance. Click Review and Launch. The warning dialog box appears because we do not configure the firewall to allow connections to port 22, Click Continue to continue.\nAt page Step 7: Review Instance Launch.\nClick Launch. In the Select an existing key pair or create a new key pair dialog box. Click to select Create a new key pair. In the Key pair name field, enter LabKeypair. Click Download Key Pair and save it to your computer. Click Launch Instances to create EC2 server. Click View Instances to return to the list of EC2 instances.\nClick the edit icon under the Name column.\nIn the Edit Name dialog box, enter Public Linux Instance. Click Save. Next, we will do the same to create an EC2 Instance Windows running in the Private subnet.\n"
},
{
	"uri": "//localhost:1313/5-portfwd/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "\rPort Forwarding is a useful way to redirect network traffic from one IP address - Port to another IP address - Port. With Port Forwarding we can access an EC2 instance located in the private subnet from our workstation.\nWe will configure Port Forwarding for the RDP connection between our machine and Private Windows Instance located in the private subnet we created for this exercise.\nCreate IAM user with permission to connect SSM Go to IAM service management console Click Users , then click Add users. At the Add user page. In the User name field, enter Portfwd. Click on Access key - Programmatic access. Click Next: Permissions. Click Attach existing policies directly.\nIn the search box, enter ssm. Click on AmazonSSMFullAccess. Click Next: Tags, click Next: Reviews. Click Create user. Save Access key ID and Secret access key information to perform AWS CLI configuration.\nInstall and Configure AWS CLI and Session Manager Plugin To perform this hands-on, make sure your workstation has AWS CLI and Session Manager Plugin installed -manager-working-with-install-plugin.html)\nMore hands-on tutorials on installing and configuring the AWS CLI can be found here.\nWith Windows, when extracting the Session Manager Plugin installation folder, run the install.bat file with Administrator permission to perform the installation.\nImplement Portforwarding Run the command below in Command Prompt on your machine to configure Port Forwarding. aws ssm start-session --target (your ID windows instance) --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region (your region) Windows Private Instance Instance ID information can be found when you view the EC2 Windows Private Instance server details.\nExample command: C:\\Windows\\system32\u0026gt;aws ssm start-session --target i-06343d7377486760c --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region ap-southeast-1 If your command gives an error like below: SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found\nProve that you have not successfully installed the Session Manager Plugin. You may need to relaunch Command Prompt after installing Session Manager Plugin.\nConnect to the Private Windows Instance you created using the Remote Desktop tool on your workstation. In the Computer section: enter localhost:9999. Return to the administration interface of the System Manager - Session Manager service. Click tab Session history. We will see session logs with Document name AWS-StartPortForwardingSession. Congratulations on completing the lab on how to use Session Manager to connect and store session logs in S3 bucket. Remember to perform resource cleanup to avoid unintended costs.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-createec2/2.1.6-createec2windows/",
	"title": "Create Private Instance",
	"tags": [],
	"description": "",
	"content": " Go to EC2 service management console Click Instances. Click Launch instances. On the Step 1: Choose an Amazon Machine Image (AMI) page. Drag the mouse down. Click Select to select AMI Microsoft Windows Server 2019 Base. On the Step 2: Choose an Instance Type page. Click on Instance type t2.micro. Click Next: Configure Instance Details. At Step 3: Configure Instance Details page In the Network section, select Lab VPC. In the Subnet section, select Lab Private Subnet. At Auto-assign Public IP select Use subnet setting (Disable) Click Next: Add Storage. Click Next: Add Tags to move to the next step. Click Next: Configure Security Group to move to the next step. On page Step 6: Configure Security Group. Select Select an existing security group. Select security group SG Private Windows Instance. Click Review and Launch. The warning dialog box appears because we do not configure the firewall to allow connections to port 22, Click Continue to continue.\nAt page Step 7: Review Instance Launch.\nClick Launch. In the Select an existing key pair or create a new key pair dialog box. Click Choose an existing key pair. In the Key pair name section, select LabKeypair. Click I acknowledge that I have access to the corresponding private key file, and that without this file, I won\u0026rsquo;t be able to log into my instance.. Click Launch Instances to create EC2 server. Click View Instances to return to the list of EC2 instances.\nClick the edit icon under the Name column.\nIn the Edit Name dialog box, enter Private Windows Instance. Click Save. Next, we will proceed to create IAM Roles to serve the Session Manager.\n"
},
{
	"uri": "//localhost:1313/6-cleanup/",
	"title": "Self-assessment",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nDelete EC2 instance Go to EC2 service management console\nClick Instances. Select both Public Linux Instance and Private Windows Instance instances. Click Instance state. Click Terminate instance, then click Terminate to confirm. Go to IAM service management console\nClick Roles. In the search box, enter SSM. Click to select SSM-Role. Click Delete, then enter the role name SSM-Role and click Delete to delete the role. Click Users. Click on user Portfwd. Click Delete, then enter the user name Portfwd and click Delete to delete the user. Delete S3 bucket Access System Manager - Session Manager service management console.\nClick the Preferences tab. Click Edit. Scroll down. In the section S3 logging. Uncheck Enable to disable logging. Scroll down. Click Save. Go to S3 service management console\nClick on the S3 bucket we created for this lab. (Example: lab-fcj-bucket-0001 ) Click Empty. Enter permanently delete, then click Empty to proceed to delete the object in the bucket. Click Exit. After deleting all objects in the bucket, click Delete\nEnter the name of the S3 bucket, then click Delete bucket to proceed with deleting the S3 bucket. Delete VPC Endpoints Go to VPC service management console Click Endpoints. Select the 4 endpoints we created for the lab including SSM, SSMMESSAGES, EC2MESSAGES, S3GW. Click Actions. Click Delete VPC endpoints. In the confirm box, enter delete.\nClick Delete to proceed with deleting endpoints. Click the refresh icon, check that all endpoints have been deleted before proceeding to the next step.\nDelete VPC Go to VPC service management console\nClick Your VPCs. Click on Lab VPC. Click Actions. Click Delete VPC. In the confirm box, enter delete to confirm, click Delete to delete Lab VPC and related resources.\n"
},
{
	"uri": "//localhost:1313/6-cleanup-copy/",
	"title": "Sharing and feedback",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nDelete EC2 instance Go to EC2 service management console\nClick Instances. Select both Public Linux Instance and Private Windows Instance instances. Click Instance state. Click Terminate instance, then click Terminate to confirm. Go to IAM service management console\nClick Roles. In the search box, enter SSM. Click to select SSM-Role. Click Delete, then enter the role name SSM-Role and click Delete to delete the role. Click Users. Click on user Portfwd. Click Delete, then enter the user name Portfwd and click Delete to delete the user. Delete S3 bucket Access System Manager - Session Manager service management console.\nClick the Preferences tab. Click Edit. Scroll down. In the section S3 logging. Uncheck Enable to disable logging. Scroll down. Click Save. Go to S3 service management console\nClick on the S3 bucket we created for this lab. (Example: lab-fcj-bucket-0001 ) Click Empty. Enter permanently delete, then click Empty to proceed to delete the object in the bucket. Click Exit. After deleting all objects in the bucket, click Delete\nEnter the name of the S3 bucket, then click Delete bucket to proceed with deleting the S3 bucket. Delete VPC Endpoints Go to VPC service management console Click Endpoints. Select the 4 endpoints we created for the lab including SSM, SSMMESSAGES, EC2MESSAGES, S3GW. Click Actions. Click Delete VPC endpoints. In the confirm box, enter delete.\nClick Delete to proceed with deleting endpoints. Click the refresh icon, check that all endpoints have been deleted before proceeding to the next step.\nDelete VPC Go to VPC service management console\nClick Your VPCs. Click on Lab VPC. Click Actions. Click Delete VPC. In the confirm box, enter delete to confirm, click Delete to delete Lab VPC and related resources.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]