[
{
	"uri": "//localhost:1313/vi/3-translatedblog/blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Tăng tốc lập kế hoạch Marketing campaign gấp 3 lần với Treasure Data AI Agents được hỗ trợ bởi Amazon Bedrock Các đội ngũ Marketing gặp nhiều khó khăn khi lập kế hoạch và triển khai chiến dịch trên nhiều kênh. Cách làm truyền thống mất hàng tháng để phối hợp giữa các hệ thống và nhóm cho việc tạo giả thuyết, phân tích đối tượng, xây dựng xây dựng hành trình khách hàng, phát triển nội dung, triển khai và đo lường. Điều này khiến các thương hiệu bỏ lỡ những thời điểm quan trọng khi khách hàng sẵn sàng tương tác.\nTreasure Data với Customer Data Platform (CDP) phục vụ nhiều thương hiệu toàn cầu, quản lý hồ sơ khách hàng trên diện rộng. Kết hợp với Amazon Web Services (AWS), công ty đã tận dụng Amazon Bedrock để tạo ra giải pháp AI-powered cho đội ngũ Marketing. Amazon Bedrock cung cấp quyền truy cập được quản lý hoàn toàn vào mô hình nền tảng hiệu năng cao để xây dựng ứng dụng generative AI. Điều này cho phép tổ chức triển khai AI Agents hiểu ngôn ngữ tự nhiên và tự động tương tác với các hệ thống khác nhau.\nBlog này mô tả cách các giải pháp AI-powered của Treasure Data, được xây dựng trên Amazon Bedrock, rút ngắn việc tạo chiến dịch từ hàng tháng xuống còn vài giờ hoặc ngày. Các giải pháp giúp Marketing và CX teams phản ứng nhanh với cơ hội thị trường, mang đến trải nghiệm cá nhân hóa quy mô lớn, đồng thời duy trì tiêu chuẩn bảo mật và quản trị phù hợp với khách hàng doanh nghiệp.\nXây dựng AI Agents dựa trên dữ liệu tin cậy Sức mạnh của AI đến từ việc kết hợp mô hình nền tảng tiên tiến với dữ liệu khách hàng chất lượng cao. Sự tích hợp giữa nền tảng Treasure Data và Amazon Bedrock cho phép chuyên gia marketing nhanh chóng phân tích dữ liệu, phân khúc khách hàng, xây dựng chân dung khách hàng và đưa ra quyết định dựa trên dữ liệu mà không cần kỹ năng kỹ thuật sâu. Cách kết hợp này giảm đáng kể thời gian tạo chiến dịch, đồng thời cải thiện độ chính xác trong việc nhắm mục tiêu khách hàng và hiệu suất tổng thể.\nHợp tác phát triển cùng AWS Treasure Data hợp tác chặt chẽ với AWS để xác định nút thắt trong quy trình chiến dịch truyền thống. Thay vì chỉ thêm giao diện chat, cả hai đã thiết kế lại workflow để tối đa hóa hiệu quả AI.\nSự hợp tác nhấn mạnh việc tìm ra sự cân bằng phù hợp giữa chuyên môn của con người và khả năng của AI. Các chuyên gia marketing vẫn giữ vai trò giám sát chiến lược, trong khi AI Agents đảm nhiệm các tác vụ phân tích tốn nhiều thời gian. Cách tiếp cận này đòi hỏi phải xây dựng các agents có thể xử lý các mối quan hệ dữ liệu phức tạp và cung cấp những insight có thể hành động được, dựa trên hành vi thực tế của khách hàng.\nSự hợp tác tập trung cân bằng giữa chuyên môn con người và AI Agents. Chuyên gia marketing vẫn giữ vai trò định hướng chiến lược, trong khi AI Agents đảm nhiệm các phân tích phức tạp, tiết kiệm thời gian. Framework multi-agent dựa trên Amazon Bedrock đã ra đời, vừa giải quyết các thách thức marketing cụ thể, vừa tuân thủ tiêu chuẩn bảo mật và sự tuân thủ của doanh nghiệp.\nAmazon Bedrock vận hành đổi mới này Treasure Data chọn Amazon Bedrock vì nó cho phép triển khai nhanh chóng, không cần xây dựng hạ tầng từ đầu, đồng thời duy trì kiểm soát và bảo mật. Amazon Bedrock đơn giản hóa việc lựa chọn mô hình nền tảng, giúp đội ngũ truy cập công nghệ mà không cần chuyên môn khoa học dữ liệu.\nNền tảng được quản lý hoàn toàn cho phép triển khai nhanh vào môi trường sản xuất. Dữ liệu khách hàng vẫn riêng tư trong mô hình trách nhiệm chia sẻ: AWS bảo mật hạ tầng, khách hàng kiểm soát dữ liệu và quyền truy cập.\nSự kết hợp giữa chuyên môn về dữ liệu khách hàng của Treasure Data và các mô hình nền tảng AI do Amazon Bedrock cung cấp, cho phép các tổ chức mở rộng các sáng kiến AI trong khi vẫn duy trì các tiêu chuẩn về bảo mật và quản trị.\nGặp gỡ các Specialized AI Agents của Treasure Data Treasure Data đã phát triển một số AI Agents chuyên dụng, được hỗ trợ bởi Amazon Bedrock, để giải quyết các thách thức marketing cụ thể. Mỗi agent tập trung giải quyết những điểm đau chính trong quy trình lập kế hoạch và triển khai chiến dịch marketing.\nAudience Agent cho phép người làm marketing khám phá và tạo ra các phân khúc khách hàng có giá trị cao từ các tín hiệu hành vi một cách nhanh chóng mà không cần SQL hay kỹ năng data nâng cao. Việc phân tích dữ liệu và phân khúc khách hàng trở nên nhanh hơn và chính xác hơn khi agent tự động xác định các pattern trong hành vi khách hàng. Hình 1 minh họa Audience Agent, công cụ này truy xuất dữ liệu khách hàng dựa trên các truy vấn. Ví dụ, khi được hỏi ‘Tôi muốn hiểu rõ hơn về những khách hàng trung thành nhất của mình’, agent sẽ xác định các thuộc tính liên quan và trình bày kết quả.\nHình 1: Bảng console Audience Agent\nDeep Research \u0026amp; Analysis Agent rút ngắn quy trình xây dựng giả thuyết từ vài tháng xuống còn chưa tới một tuần. Thay vì tốn nhiều thời gian cho phân tích thủ công và marketing, các đội ngũ khách hàng có thể tạo ra các giả thuyết chất lượng cao dựa trên các tín hiệu hành vi, giúp định hướng chiến lược, thử nghiệm, và quyết định triển khai. Nền tảng Treasure Data’s Deep Insight Platform cung cấp khả năng “Question Management”, cho phép người dùng đặt các câu hỏi để thực hiện nhiều phân tích như Churn Rate Trend và Email Performance Analysis như minh họa ở Hình 2.\nHình 2: Nền tảng Treasure Data Deep Insight\nĐược cung cấp như một phần của Treasure Data’s CDP Trade-Up program, Migration Agent giúp tăng tốc quá trình chuyển đổi từ các customer data platform hiện có lên đến 60%. Agent này trích xuất các queries, segments và transformation logic từ hệ thống hiện tại, đồng thời tự động tạo ra SQL, pipelines và orchestration workflows. Nhờ vậy, các tổ chức có thể giữ nguyên segments, workflows và business logic khi di chuyển dữ liệu, tránh phải bắt đầu lại từ đầu.\nCác agents này sử dụng retrieval augmented generation (RAG), kết hợp khả năng xử lý dữ liệu với sức mạnh inference của Amazon Bedrock, để cung cấp các phản hồi chính xác và dựa trên dữ liệu. Điều này đảm bảo các gợi ý từ AI phản ánh hành vi thực tế của khách hàng thay vì chỉ là các khuyến nghị chung chung.\nGiới thiệu Treasure Data’s AI Agent Foundry Trong khi các agents xây dựng sẵn giải quyết những thách thức marketing phổ biến, khách hàng của Treasure Data lại bày tỏ nhu cầu tạo ra các customized agents được thiết kế riêng cho yêu cầu kinh doanh độc đáo và các use case đặc thù theo ngành. AI Agent Foundry ra đời như một giải pháp cho nhu cầu này.\nAI Agent Foundry đóng vai trò là nền tảng để xây dựng các custom AI agents phù hợp với nhu cầu kinh doanh cụ thể. Các nhóm marketing, customer experience và data có thể tạo, tinh chỉnh và triển khai agents mà không cần kiến thức kỹ thuật chuyên sâu. Những use case có tác động lớn có thể bao gồm journey orchestration, giám sát data health và tối ưu hóa campaign dành riêng cho tổ chức của họ.\nFoundry tích hợp sẵn các tính năng bảo mật, kiểm soát quyền truy cập, khả năng audit và quản lý access, đáp ứng các yêu cầu quản trị doanh nghiệp. Các tổ chức có thể thử nghiệm các khả năng AI và triển khai agents trong khi vẫn duy trì được tính bảo mật dữ liệu, quyền riêng tư và tuân thủ quy định. Cách tiếp cận này cho phép khách hàng xây dựng các agents đáp ứng được động lực thị trường và quy trình kinh doanh đặc thù của họ.\nỨng dụng thực tế thúc đẩy hiệu quả Các specialized agents giải quyết nhiều use case marketing quan trọng thông qua việc tích hợp với Amazon Bedrock. Decision support giúp chuyên gia marketing đánh giá đồng thời nhiều yếu tố khi xác định campaign targeting, messaging và channel selection. AI đưa ra các khuyến nghị dựa trên phân tích dữ liệu toàn diện thay vì chỉ dựa vào trực giác.\nNhiều thành viên trong team có thể cộng tác với AI agents cùng lúc, giúp dân chủ hóa khả năng tiếp cận các nhu cầu khách hàng trong toàn bộ tổ chức marketing. Năng lực này loại bỏ các nghẽn cổ chai do hạn chế về chuyên môn kỹ thuật trong các đội marketing.\nCác agents liên tục học hỏi từ tương tác khách hàng và hiệu suất chiến dịch, cho phép tổ chức tinh chỉnh cách tiếp cận và đạt được kết quả tốt hơn thông qua iteration nhanh chóng và tối ưu.\nTác động thực tế: Nobitel case study Nobitel Co., Ltd., một công ty hàng đầu trong lĩnh vực dịch vụ sức khỏe và thể thao, vận hành Dr. Stretch, chuỗi chuyên về stretching với hơn 240 cơ sở trên khắp Nhật Bản. Công ty gặp thách thức trong hoạt động marketing, khi việc lập kế hoạch chiến dịch thủ công và tình trạng data silo khiến các đội ngũ không chuyên kỹ thuật không thể tiếp cận được thấu hiểu khách hàng và cung cấp các ưu đãi cá nhân hóa kịp thời.\nĐể giải quyết những thách thức này, Nobitel đã triển khai Treasure Data’s AI Agent Foundry, được xây dựng trên AWS AI/ML services bao gồm Amazon Bedrock. Việc triển khai này đã thay đổi cách vận hành marketing, cho phép người làm marketing không chuyên kỹ thuật thực hiện chiến dịch cá nhân hóa mà không cần kỹ năng dữ liệu nâng cao. Kết quả đạt được bao gồm tốc độ lập kế hoạch chiến dịch nhanh hơn gấp 3 lần và cải thiện 20% hiệu quả hoạt động tại cửa hàng. Tìm hiểu thêm về sự chuyển đổi của Nobitel trong case study của họ.\nTương lai của marketing được hỗ trợ bởi AI AI agents đánh dấu sự khởi đầu của một quá trình chuyển đổi sẽ định hình lại hoạt động marketing và trải nghiệm khách hàng. Trong tương lai, các agents sẽ có thể thử nghiệm nhiều biến thể thông điệp, tạo ra nội dung sáng tạo, điều phối các chiến dịch đa kênh và tối ưu hóa chi tiêu theo thời gian thực trên nhiều thiết bị và khu vực.\nCác chuyên gia marketing và trải nghiệm khách hàng sẽ phát triển từ vai trò người thực thi chiến dịch sang vai trò điều phối chiến lược. Câu hỏi quan trọng đặt ra là liệu hạ tầng dữ liệu có thể hỗ trợ nhiều chiến dịch tự động chạy đồng thời với độ chính xác và khả năng kiểm soát hay không.\nTương lai này đòi hỏi nền tảng dữ liệu vững chắc, năng lực AI tiên tiến và các framework quản trị đảm bảo niềm tin cũng như tuân thủ ở quy mô lớn. Những tổ chức xây dựng hạ tầng này ngay từ hôm nay sẽ có lợi thế để tận dụng tối đa hoạt động marketing và trải nghiệm khách hàng tự động.\nChuyển đổi marketing thông qua AI và dữ liệu Các AI agents chuyên dụng và AI Agent Foundry của Treasure Data, được hỗ trợ bởi Amazon Bedrock, đại diện cho một sự chuyển đổi căn bản trong cách các nhóm marketing, trải nghiệm khách hàng và dữ liệu khai thác giá trị từ dữ liệu khách hàng. Bằng cách kết hợp dữ liệu đáng tin cậy với các mồ hình nền tảng tiên tiến, các nhóm có thể phân tích dữ liệu, tạo phân khúc khách hàng, xây dựng chân dung khách hàng, và đưa ra quyết định chiến lược chỉ trong vài giờ thay vì vài tháng.\nSự chuyển đổi này dân chủ hóa quyền tiếp cận thấu hiểu khách hàng và tự động hóa các tác vụ phân tích phức tạp. Các nhóm marketing có thể phản ứng nhanh hơn trước cơ hội thị trường và đạt được kết quả tốt hơn thông qua quá trình lặp cải tiến nhanh chóng. Giải pháp này cho thấy rằng một marketing hiệu quả đòi hỏi cả intelligent agents lẫn hạ tầng dữ liệu vững chắc để thực sự phát huy sức mạnh.\nBảo mật và tuân thủ vẫn là trách nhiệm được chia sẻ giữa AWS và khách hàng. AWS cung cấp một nền tảng bảo mật và tuân thủ thông qua Amazon Bedrock, trong khi khách hàng duy trì quyền kiểm soát đối với dữ liệu và chính sách truy cập của mình. Cách tiếp cận này cho phép các tổ chức đổi mới với AI đồng thời vẫn đáp ứng được các yêu cầu về quản trị.\nKết luận Treasure Data’s AI Agent Foundry và các AI agent dựng sẵn, được hỗ trợ bởi Amazon Bedrock, đã biến việc tạo chiến dịch marketing từ một quy trình kéo dài hàng tháng thành chỉ còn vài giờ hoặc vài ngày. Các giải pháp AI này cho phép marketer nhanh chóng phân tích dữ liệu, tạo segments, xây dựng personas, và đưa ra quyết định dựa trên dữ liệu mà không cần chuyên môn kỹ thuật chuyên sâu. Bằng cách dân chủ hóa quyền truy cập vào yêu cầu khách hàng và tự động hóa các tác vụ phân tích phức tạp, tất cả đều được vận hành nhờ các foundation models của Amazon Bedrock, các đội marketing giờ đây có thể phản ứng nhanh hơn với cơ hội thị trường và đạt được kết quả tốt hơn thông qua lặp nhanh và tối ưu hóa liên tục.\nTreasure Data – AWS Partner Spotlight Treasure Data, một AWS partner, là Intelligent Customer Data Platform được xây dựng đặc biệt để đáp ứng quy mô enterprise. Được các thương hiệu lớn như Yum! Brands, Stellantis, AXA và hơn 80 công ty trong Global 2000 tin tưởng, Treasure Data là nơi mà niềm tin, hiệu suất và kiến trúc AI-first hội tụ để thúc đẩy doanh thu với trải nghiệm khách hàng siêu cá nhân hóa, giảm chi phí marketing và hạn chế rủi ro. Treasure Data cung cấp cả các agents dựng sẵn và AI Agent Foundry, cho phép các đội ngũ dựa trên dữ liệu hoặc đối tác sử dụng, tạo và triển khai AI Agents trên nền tảng Treasure Data và trong toàn bộ workflows của họ, đồng thời khai thác dữ liệu trong một môi trường Treasure Data đáng tin cậy.\nRonak Shah Ronak Shah là Kiến trúc sư Giải pháp Cấp cao (Principal Partner Solution Architect) trong nhóm Ngành Verticals của AWS, đặt tại khu vực New York (Mỹ). Ông hợp tác với các đối tác AWS trong lĩnh vực Bán lẻ (Retail) và Hàng tiêu dùng nhanh (CPG) để cùng sáng tạo các giải pháp mới. Ông quan tâm đến các xu hướng mới trong bán lẻ và xây dựng những ứng dụng đổi mới trong thương mại điện tử, chuỗi cung ứng, trải nghiệm khách hàng và công nghệ marketing.\rHiroshi Nakamura Hiroshi Nakamura là lãnh đạo công nghệ (CTO) \u0026 Phó Chủ tịch Kỹ thuật (VP Engineering) tại Treasure Data từ tháng 10 năm 2014. Ông có kinh nghiệm sâu rộng trong kỹ thuật phần mềm và kiến trúc hệ thống. Trước đó, ông đã đóng góp nhiều cho cộng đồng mã nguồn mở, đặc biệt với các dự án như Ruby và JRuby. Ông tốt nghiệp Thạc sĩ Khoa học \u0026 Kỹ thuật tại Đại học Waseda.\rPranjal Gururani Pranjal Gururani là Kiến trúc sư Giải pháp (Solutions Architect) tại AWS, làm việc tại Seattle (Mỹ). Ông hỗ trợ nhiều khách hàng khác nhau trong việc kiến tạo giải pháp đám mây để đáp ứng các thách thức kinh doanh. Bên ngoài công việc, ông thích leo núi, chèo thuyền kayak, nhảy dù và dành thời gian cho gia đình.\r"
},
{
	"uri": "//localhost:1313/vi/3-translatedblog/blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "Xây dựng các agent AI tạo sinh có khả năng phục hồi Các agent AI tạo sinh trong môi trường sản xuất đòi hỏi các chiến lược phục hồi vượt ra ngoài các mẫu phần mềm truyền thống. Các agent AI đưa ra quyết định tự chủ, tiêu thụ tài nguyên tính toán đáng kể và tương tác với các hệ thống bên ngoài theo những cách không thể đoán trước. Những đặc điểm này tạo ra các chế độ lỗi mà các phương pháp tiếp cận khả năng phục hồi thông thường có thể không giải quyết được.\nBài đăng này trình bày một khuôn khổ để phân tích rủi ro về khả năng phục hồi của agent AI áp dụng cho hầu hết các kiến trúc phát triển và triển khai AI. Chúng tôi cũng khám phá các chiến lược thực tế để giúp ngăn chặn, phát hiện và giảm thiểu các thách thức về khả năng phục hồi phổ biến nhất khi triển khai và mở rộng quy mô các agent AI.\nCác khía cạnh rủi ro về khả năng phục hồi của agent AI tạo sinh Để xác định các rủi ro về khả năng phục hồi, chúng tôi chia nhỏ các hệ thống agent AI tạo sinh thành bảy khía cạnh:\nFoundation models – Foundation models (FMs) cung cấp khả năng suy luận và lập kế hoạch cốt lõi. Lựa chọn triển khai của bạn quyết định trách nhiệm và chi phí phục hồi của bạn. Ba phương pháp triển khai là tự quản lý hoàn toàn như sử dụng Amazon Elastic Compute Cloud (Amazon EC2), các dịch vụ được quản lý dựa trên máy chủ như sử dụng Amazon SageMaker AI, hoặc các dịch vụ được quản lý không có máy chủ như Amazon Bedrock. Agent orchestration – Thành phần này kiểm soát cách nhiều agent và công cụ AI phối hợp để đạt được các mục tiêu phức tạp, chứa logic để lựa chọn công cụ, trình kích hoạt leo thang của con người và quản lý quy trình làm việc nhiều bước. Agent deployment infrastructure – Cơ sở hạ tầng bao gồm phần cứng và hệ thống cơ bản nơi các agent chạy. Các tùy chọn cơ sở hạ tầng bao gồm sử dụng các phiên bản EC2 được quản lý hoàn toàn, các dịch vụ được quản lý như Amazon Elastic Container Services (Amazon ECS) và các dịch vụ được quản lý chuyên biệt được thiết kế riêng cho việc triển khai agent, chẳng hạn như Amazon Bedrock AgentCore Runtime. Knowledge base – Knowledge base bao gồm lưu trữ cơ sở dữ liệu vector, các mô hình nhúng và các đường ống dữ liệu tạo ra các nhúng vector, tạo thành nền tảng cho các ứng dụng Retrieval Augmented Generation (RAG). Amazon Bedrock Knowledge Bases hỗ trợ các quy trình làm việc RAG được quản lý hoàn toàn. Agent tools – Điều này bao gồm các công cụ API, máy chủ Model Context Protocol (MCP), quản lý bộ nhớ và các tính năng bộ nhớ đệm nhắc lệnh giúp mở rộng khả năng của agent. Security and compliance – Thành phần này bao gồm các kiểm soát bảo mật của người dùng và agent cũng như giám sát tuân thủ nội dung, hỗ trợ xác thực, ủy quyền và xác thực nội dung phù hợp. Bảo mật bao gồm xác thực trong nước quản lý quyền truy cập của người dùng vào các agent và xác thực và ủy quyền ngoài nước quản lý quyền truy cập của các agent vào các tài nguyên khác. Ủy quyền ngoài nước phức tạp hơn vì các agent có thể yêu cầu danh tính riêng của chúng. Amazon Bedrock AgentCore Identity là dịch vụ quản lý danh tính và thông tin xác thực được thiết kế riêng cho các agent AI, cung cấp khả năng xác thực và ủy quyền trong và ngoài nước. Để giúp ngăn chặn vi phạm tuân thủ, các tổ chức nên thiết lập các chính sách AI có trách nhiệm toàn diện. Amazon Bedrock Guardrails cung cấp các biện pháp bảo vệ có thể định cấu hình để thực hiện chính sách AI có trách nhiệm. Evaluation and observability – Các hệ thống này theo dõi các chỉ số từ thống kê cơ sở hạ tầng cơ bản đến các dấu vết cụ thể của AI chi tiết, bao gồm đánh giá hiệu suất liên tục và phát hiện các sai lệch hành vi. Đánh giá và khả năng quan sát của agent đòi hỏi sự kết hợp của các chỉ số hệ thống truyền thống và các tín hiệu dành riêng cho agent, chẳng-hạn như dấu vết suy luận và kết quả gọi công cụ. Sơ đồ sau đây minh họa các khía cạnh này. Cấu hình này cung cấp khả năng hiển thị vào các ứng dụng của agent, cho phép các phiên tiếp theo cung cấp phân tích khả năng phục hồi được nhắm mục tiêu và các khuyến nghị giảm thiểu. Sơ đồ sau minh họa các khía cạnh này.\nCấu hình này cung cấp khả năng quan sát các ứng dụng của tác nhân, cho phép các phiên làm việc sau đó đưa ra phân tích khả năng phục hồi có mục tiêu và các khuyến nghị giảm thiểu.\n5 vấn đề về khả năng phục hồi hàng đầu đối với các agent và kế hoạch giảm thiểu Resilience Analysis Framework xác định các chế độ lỗi cơ bản mà các hệ thống sản xuất nên tránh. Trong bài đăng này, chúng tôi xác định năm chế độ lỗi chính của các agent AI tạo sinh và cung cấp các chiến lược có thể giúp thiết lập các thuộc tính phục hồi.\nShared fate Shared fate xảy ra khi một lỗi trong một thành phần của agent lan truyền qua các ranh giới hệ thống, ảnh hưởng đến toàn bộ agent. Fault isolation là thuộc tính mong muốn. Để đạt được fault isolation, bạn phải hiểu cách các thành phần của agent tương tác và xác định các phụ thuộc được chia sẻ của chúng.\nMối quan hệ giữa FMs, knowledge bases và agent orchestration đòi hỏi ranh giới cô lập rõ ràng. Ví dụ, trong các ứng dụng RAG, knowledge bases có thể trả về kết quả tìm kiếm không liên quan. Việc triển khai các biện pháp bảo vệ với kiểm tra mức độ liên quan có thể giúp ngăn các lỗi truy vấn này lan truyền qua phần còn lại của quy trình làm việc của agent.\nCác công cụ phải phù hợp với ranh giới fault isolation để chứa tác động trong trường hợp có lỗi. Khi xây dựng các công cụ tùy chỉnh, hãy thiết kế mỗi công cụ như một miền ngăn chặn riêng. Khi sử dụng máy chủ MCP hoặc các công cụ hiện có, hãy đảm bảo bạn sử dụng các lược đồ yêu cầu/phản hồi nghiêm ngặt, có phiên bản và xác thực chúng ở ranh giới. Thêm các xác thực ngữ nghĩa như phạm vi ngày, quy tắc giữa các trường và kiểm tra độ mới của dữ liệu. Các công cụ nội bộ cũng có thể được triển khai trên các Vùng sẵn sàng khác nhau của AWS để có thêm khả năng phục hồi.\nỞ khía cạnh orchestration, hãy triển khai các bộ ngắt mạch giám sát tỷ lệ lỗi và độ trễ, kích hoạt khi các phụ thuộc không khả dụng. Đặt giới hạn thử lại có giới hạn với backoff theo cấp số nhân và jitter để kiểm soát chi phí và tranh chấp. Để có khả năng phục hồi kết nối, hãy triển khai ánh xạ lỗi JSON-RPC mạnh mẽ và thời gian chờ cho mỗi cuộc gọi, đồng thời duy trì các nhóm kết nối lành mạnh với các công cụ, máy chủ MCP và các dịch vụ hạ nguồn. Khía cạnh orchestration cũng nên quản lý các phương án dự phòng tương thích với hợp đồng—định tuyến từ một công cụ hoặc máy chủ MCP bị lỗi sang các phương án thay thế—trong khi vẫn duy trì các lược đồ nhất quán và cung cấp chức năng bị suy giảm.\nKhi ranh giới cô lập bị lỗi, bạn có thể triển khai graceful degradation để duy trì chức năng cốt lõi trong khi các tính năng nâng cao không khả dụng. Tiến hành kiểm tra khả năng phục hồi với việc tiêm lỗi dành riêng cho AI, chẳng hạn như mô phỏng lỗi suy luận mô hình hoặc sự không nhất quán của knowledge base, để kiểm tra ranh giới cô lập của bạn trước khi sự cố xảy ra trong sản xuất.\nInsufficient capacity Tải quá mức có thể làm quá tải ngay cả các hệ thống được cung cấp tốt, có khả năng dẫn đến suy giảm hiệu suất hoặc lỗi hệ thống. Đủ dung lượng đảm bảo hệ thống của bạn có các tài nguyên cần thiết để xử lý cả các mẫu lưu lượng truy cập dự kiến ​​và các đợt tăng đột biến bất ngờ về nhu cầu.\nLập kế hoạch dung lượng agent AI bao gồm dự báo nhu cầu, đánh giá tài nguyên và phân tích hạn ngạch. Việc xem xét chính khi lập kế hoạch dung lượng là ước tính Requests Per Minute (RPM) và Tokens Per Minute (TPM). Tuy nhiên, việc ước tính RPM và TPM đặt ra những thách thức riêng do bản chất ngẫu nhiên của các agent. Các agent AI thường sử dụng xử lý đệ quy, trong đó công cụ suy luận của agent gọi lặp đi lặp lại các FM cho đến khi đạt được câu trả lời cuối cùng. Điều này tạo ra hai khó khăn lớn trong việc lập kế hoạch. Đầu tiên, số lượng các cuộc gọi lặp lại rất khó dự đoán vì nó dựa trên độ phức tạp của nhiệm vụ và các đường dẫn suy luận. Thứ hai, độ dài token của mỗi cuộc gọi cũng khó dự đoán vì nó bao gồm lời nhắc của người dùng, hướng dẫn hệ thống, các bước suy luận do agent tạo ra và lịch sử cuộc trò chuyện. Hiệu ứng kép này làm cho việc lập kế hoạch dung lượng cho các agent trở nên khó khăn.\nThông qua phân tích heuristic trong quá trình phát triển, các nhóm có thể đặt giới hạn đệ quy hợp lý để giúp ngăn chặn các vòng lặp dư thừa và tiêu thụ tài nguyên không kiểm soát. Ngoài ra, vì đầu ra của agent trở thành đầu vào cho các lần đệ quy tiếp theo, việc quản lý các token hoàn thành tối đa giúp kiểm soát một thành phần của việc tiêu thụ token ngày càng tăng trong các chuỗi suy luận đệ quy.\nCác phương trình sau đây giúp chuyển đổi cấu hình của agent thành các ước tính dung lượng này:\nRPM = Số luồng trung bình ở cấp agent mỗi phút * Số lần gọi FM trung bình mỗi phút trong một luồng = Số luồng trung bình ở cấp agent mỗi phút * (1 + 60/(số token hoàn thành tối đa/TPS))\nToken per second (TPS) khác nhau đối với mỗi mô hình và có thể được tìm thấy trong tài liệu phát hành mô hình và kết quả benchmark nguồn mở, chẳng hạn như phân tích nhân tạo. Phép tính này giả định không có tính năng bộ nhớ đệm nhắc lệnh nào được triển khai.\nTPM = RPM * Độ dài token đầu vào trung bình = RPM * (độ dài lời nhắc hệ thống + độ dài lời nhắc người dùng + số token hoàn thành tối đa * (giới hạn đệ quy -1)/giới hạn đệ quy)\nPhép tính này giả định rằng không có tính năng lưu bộ nhớ đệm prompt nào được triển khai.\nKhông giống như các công cụ bên ngoài nơi khả năng phục hồi được quản lý bởi các nhà cung cấp bên thứ ba, các công cụ được phát triển trong nội bộ phụ thuộc vào cấu hình phù hợp của nhóm phát triển để mở rộng quy mô dựa trên nhu-cầu. Khi nhu cầu tài nguyên tăng đột biến, chỉ các công cụ bị ảnh hưởng mới cần mở rộng quy mô.\nVí dụ, các hàm AWS Lambda có thể được chuyển đổi thành các công cụ tương thích với MCP bằng cách sử dụng Amazon Bedrock AgentCore Gateway. Nếu các công cụ phổ biến khiến các hàm Lambda đạt đến giới hạn dung lượng, bạn có thể tăng giới hạn thực thi đồng thời ở cấp tài khoản hoặc triển khai đồng thời được cung cấp để xử lý tải tăng lên.\nĐối với các kịch bản liên quan đến nhiều nhóm hành động thực thi đồng thời, các kiểm soát đồng thời dành riêng của hàm Lambda cung cấp sự cô lập tài nguyên thiết yếu bằng cách phân bổ dung lượng chuyên dụng cho mỗi nhóm hành động. Điều này giúp ngăn một công cụ duy nhất tiêu thụ tất cả các tài nguyên có sẵn trong các lần gọi được dàn xếp, tạo điều kiện thuận lợi cho sự sẵn có của tài nguyên cho các chức năng có mức độ ưu tiên cao.\nKhi đạt đến giới hạn dung lượng, bạn có thể sử dụng hàng đợi yêu cầu thông minh với phân bổ dựa trên mức độ ưu tiên để đảm bảo các dịch vụ thiết yếu tiếp tục hoạt động. Việc triển khai graceful degradation trong các giai đoạn tải cao có thể hữu ích. Điều này duy trì chức năng cốt lõi trong khi tạm thời giảm các tính năng không thiết yếu.\nExcessive latency Độ trễ quá mức làm ảnh hưởng đến trải nghiệm người dùng, giảm thông lượng và làm suy yếu giá trị thực tế của các agent AI trong sản xuất. Việc phát triển khối lượng công việc của agent đòi hỏi sự cân bằng giữa tốc độ, chi phí và độ chính xác. Độ chính xác là nền tảng để các agent AI có được lòng tin của người dùng. Để đạt được độ chính xác cao, cần cho phép các agent thực hiện nhiều lần lặp lại suy luận, điều này chắc chắn sẽ tạo ra những thách thức về độ trễ.\nViệc quản lý kỳ vọng của người dùng trở nên quan trọng—thiết lập các chỉ số service level objective (SLO) trước khi bắt đầu dự án sẽ đặt ra các mục tiêu thực tế cho thời gian phản hồi của agent. Các nhóm nên xác định các ngưỡng độ trễ cụ thể cho các khả năng khác nhau của agent, chẳng hạn như phản hồi dưới giây cho các truy vấn đơn giản so với các cửa sổ dài hơn cho các tác vụ phân tích đòi hỏi nhiều tương tác công cụ hoặc các chuỗi suy luận mở rộng. Việc truyền đạt rõ ràng thời gian phản hồi dự kiến ​​giúp ngăn ngừa sự thất vọng của người dùng và cho phép đưa ra các quyết định thiết kế hệ thống phù hợp.\nPrompt engineering mang lại cơ hội lớn nhất để cải thiện độ trễ bằng cách giảm các vòng lặp suy luận không cần thiết. Các lời nhắc mơ hồ đưa các agent vào các chu kỳ cân nhắc sâu rộng, trong khi các hướng dẫn rõ ràng giúp tăng tốc độ ra quyết định. Yêu cầu một agent \u0026ldquo;phê duyệt nếu trường hợp sử dụng có giá trị chiến lược\u0026rdquo; tạo ra một chuỗi suy luận phức tạp. Agent trước tiên phải xác định các tiêu chí giá trị chiến lược, sau đó đánh giá các tiêu chí nào áp dụng và cuối cùng xác định các ngưỡng ý nghĩa. Ngược lại, việc nêu rõ các tiêu chí trong lời nhắc hệ thống có thể giảm đáng kể các lần lặp lại của agent.\nSau đây là một ví dụ về hướng dẫn agent không rõ ràng:\nBạn là người phê duyệt trường hợp sử dụng AI tạo sinh.\nVai trò của bạn là đánh giá các yêu cầu xây dựng agent GenAI bằng cách phân tích cẩn thận thông tin do người dùng cung cấp và đưa ra quyết định phê duyệt. Vui lòng làm theo các hướng dẫn sau:\n\u0026lt;instructions\u0026gt;\nPhân tích cẩn thận thông tin do người dùng cung cấp và thu thập thông tin về trường hợp sử dụng, chẳng hạn như người bảo trợ cho trường hợp sử dụng, tầm quan trọng của trường hợp sử dụng và các giá trị tiềm năng mà nó có thể mang lại.\nPhê duyệt trường hợp sử dụng nếu nó có người bảo trợ cấp cao và có giá trị chiến lược.\n\u0026lt;/instructions\u0026gt;\nSau đây là một ví dụ về hướng dẫn agent rõ ràng, được định nghĩa tốt: Bạn là người phê duyệt trường hợp sử dụng AI tạo sinh. Vai trò của bạn là đánh giá các yêu cầu xây dựng agent Gen AI bằng cách phân tích cẩn thận thông tin do người dùng cung cấp và đưa ra quyết định phê duyệt dựa trên các tiêu chí cụ thể.\nVui lòng tuân thủ nghiêm ngặt các hướng dẫn sau:\n\u0026lt;instructions\u0026gt;\nPhân tích cẩn thận thông tin do người dùng cung cấp. Thu thập câu trả lời cho các câu hỏi sau:\n\u0026lt;question_1\u0026gt;Trường hợp sử dụng có người bảo trợ kinh doanh từ cấp VP trở lên không?\u0026lt;/question_1\u0026gt;\n\u0026lt;question_2\u0026gt;Agent này dự kiến sẽ mang lại giá trị gì? Câu trả lời có thể ở dạng số giờ tiết kiệm được mỗi tháng cho các tác vụ nhất định, hoặc các giá trị doanh thu bổ sung.\u0026lt;/question_2\u0026gt;\n\u0026lt;question_3\u0026gt;Nếu trường hợp sử dụng dành cho khách hàng bên ngoài, vui lòng cung cấp thông tin hỗ trợ về nhu cầu.\u0026lt;/question_3\u0026gt;\nĐánh giá yêu cầu dựa trên các tiêu chí phê duyệt sau:\n\u0026lt;criteria_1\u0026gt;Trường hợp sử dụng có người bảo trợ kinh doanh ở cấp VP trở lên. Đây là một tiêu chí cứng.\u0026lt;/criteria_1\u0026gt;\n\u0026lt;criteria_2\u0026gt;Trường hợp sử dụng có thể mang lại giá trị $ đáng kể, được tính bằng mức tăng năng suất hoặc tăng doanh thu. Đây là một tiêu chí mềm.\u0026lt;/criteria_2\u0026gt;\n\u0026lt;criteria_3\u0026gt;Có bằng chứng chắc chắn rằng trường hợp sử dụng/tính năng này được khách hàng yêu cầu. Đây là một tiêu chí mềm.\u0026lt;/criteria_3\u0026gt;\nDựa trên đánh giá, đưa ra quyết định phê duyệt hoặc từ chối trường hợp sử dụng.\nPhê duyệt: Nếu tiêu chí cứng được đáp ứng, và ít nhất một trong các tiêu chí mềm được đáp ứng Từ chối: Tiêu chí cứng không được đáp ứng, hoặc không có tiêu chí mềm nào được đáp ứng. \u0026lt;/instructions\u0026gt;\nPrompt caching giúp giảm độ trễ đáng kể bằng cách lưu trữ các tiền tố lời nhắc lặp lại giữa các yêu cầu. Amazon Bedrock prompt caching có thể giảm độ trễ lên đến 85% cho các mô hình được hỗ trợ, đặc biệt mang lại lợi ích cho các agent có lời nhắc hệ thống dài và thông tin ngữ cảnh không thay đổi qua các phiên.\nAsynchronous processing cho các agent và công cụ giúp giảm độ trễ bằng cách cho phép thực thi song song. Các quy trình làm việc đa agent đạt được tốc độ tăng đáng kể khi các agent độc lập thực thi song song thay vì chờ đợi hoàn thành tuần tự. Đối với các agent có công cụ, xử lý không đồng bộ cho phép tiếp tục suy luận và chuẩn bị các hành động tiếp theo trong khi các công cụ thực thi ở chế độ nền, tối ưu hóa quy trình làm việc bằng cách chồng chéo xử lý nhận thức với các hoạt động I/O.\nCác kiểm tra bảo mật và tuân thủ phải giảm thiểu tác động đến độ trễ trong khi vẫn duy trì sự bảo vệ trên các khía cạnh. Các agent kiểm duyệt nội dung triển khai quét tuân thủ theo luồng (streaming) để đánh giá đầu ra của agent trong quá trình tạo ra thay vì chờ đợi phản hồi hoàn chỉnh, gắn cờ nội dung có khả năng gây vấn đề trong thời gian thực trong khi cho phép nội dung an toàn được lưu thông ngay lập tức.\nPhản hồi của agent không chính xác Đầu ra chính xác đảm bảo agent AI của bạn hoạt động đáng tin cậy trong phạm vi được xác định, cung cấp các phản hồi chính xác và nhất quán đáp ứng kỳ vọng của người dùng và yêu cầu kinh doanh. Tuy nhiên, cấu hình sai, lỗi phần mềm và hiện tượng ảo giác của mô hình có thể làm ảnh hưởng đến chất lượng đầu ra, dẫn đến các phản hồi không chính xác làm suy yếu lòng tin của người dùng.\nĐể cải thiện độ chính xác, hãy sử dụng các luồng điều phối xác định (deterministic) bất cứ khi nào có thể. Việc để các agent dựa vào các LLM để tự ứng biến khi thực hiện nhiệm vụ sẽ tạo cơ hội đi chệch khỏi con đường bạn đã định. Thay vào đó, hãy xác định các quy trình làm việc rõ ràng chỉ định cách các agent nên tương tác và sắp xếp thứ tự các hoạt động của chúng. Cách tiếp cận có cấu trúc này làm giảm cả lỗi gọi giữa các agent và lỗi gọi công cụ. Ngoài ra, việc triển khai các input and output guardrails giúp tăng cường đáng kể độ chính xác của agent. Amazon Bedrock Guardrails có thể quét đầu vào của người dùng để kiểm tra tuân thủ trước khi gọi mô hình, và cung cấp xác thực đầu ra để phát hiện hiện tượng ảo giác, các phản hồi có hại, thông tin nhạy cảm và các chủ đề bị chặn.\nKhi các vấn đề về chất lượng phản hồi xảy ra, bạn có thể triển khai human-in-the-loop validation (xác thực có sự can thiệp của con người) cho các quyết định quan trọng nơi độ chính xác là thiết yếu, và triển khai các cơ chế thử lại tự động với các lời nhắc được tinh chỉnh khi các phản hồi ban đầu không đáp ứng tiêu chuẩn chất lượng.\nSingle point of failure Redundancy (sự dự phòng) tạo ra nhiều con đường dẫn đến thành công bằng cách giảm thiểu các điểm lỗi đơn lẻ có thể gây ra suy yếu trên toàn hệ thống. Các điểm lỗi đơn lẻ làm suy yếu sự dự phòng khi nhiều thành phần phụ thuộc vào một tài nguyên hoặc dịch vụ duy nhất, tạo ra các lỗ hổng vượt qua các ranh giới bảo vệ. Sự dự phòng hiệu quả đòi hỏi cả các thành phần dự phòng và các đường dẫn dự phòng, đảm bảo rằng nếu một thành phần bị lỗi, các thành phần thay thế có thể tiếp quản, và nếu một đường dẫn không khả dụng, lưu lượng truy cập có thể đi qua các tuyến đường khác nhau.\nCác agent yêu cầu sự dự phòng phối hợp cho các FM của chúng. Nếu các mô hình được tự quản lý, bạn có thể triển khai multi-Region model deployment (triển khai mô hình đa Vùng) với automated failover (chuyển đổi dự phòng tự động). Khi sử dụng các dịch vụ được quản lý, Amazon Bedrock cung cấp cross-Region inference (suy luận chéo Vùng) để cung cấp sự dự phòng tích hợp sẵn cho các mô hình được hỗ trợ, tự động định tuyến các yêu cầu đến các Vùng AWS thay thế khi các điểm cuối chính gặp sự cố.\nAgent sẽ tự động định tuyến đến các công cụ thay thế cung cấp chức năng tương tự, ngay cả khi chúng kém tinh vi hơn. Ví dụ, khi knowledge base của trợ lý trò chuyện nội bộ bị lỗi, nó có thể chuyển sang công cụ tìm kiếm để cung cấp đầu ra thay thế cho người dùng.\nViệc duy trì tính nhất quán về quyền trên các môi trường dự phòng là điều cần thiết. Điều này giúp ngăn ngừa các lỗ hổng bảo mật trong các kịch bản chuyển đổi dự phòng. Vì các kiểm soát truy cập quá dễ dãi gây ra rủi ro bảo mật đáng kể, điều quan trọng là phải xác thực rằng cả quyền của người dùng cuối và quyền truy cập ở cấp công cụ đều giống hệt nhau giữa các thành phần chính và thành phần chuyển đổi dự phòng. Tính nhất quán này đảm bảo các ranh giới bảo mật được duy trì bất kể môi trường nào đang tích cực phục vụ các yêu cầu, giúp ngăn chặn việc leo thang đặc quyền hoặc truy cập trái phép có thể xảy ra khi hệ thống chuyển đổi giữa các mô hình quyền khác nhau trong quá trình chuyển đổi hoạt động.\nOperational excellence: Tích hợp các phương pháp truyền thống và các thực hành chuyên biệt cho AI. Operational excellence trong AI của agent tích hợp các phương pháp DevOps đã được chứng minh với các yêu cầu dành riêng cho AI để chạy các hệ thống của agent một cách đáng tin cậy trong sản xuất. Các đường ống continuous integration and continuous delivery (CI/CD) điều phối toàn bộ vòng đời của agent và infrastructure as code (IaC) chuẩn hóa việc triển khai trên các môi trường, giảm lỗi thủ công và cải thiện khả năng tái tạo.\nKhả năng quan sát của agent đòi hỏi sự kết hợp giữa các chỉ số truyền thống và các tín hiệu dành riêng cho agent như dấu vết suy luận và kết quả gọi công cụ. Mặc dù các chỉ số và nhật ký hệ thống truyền thống có thể được lấy từ Amazon CloudWatch, nhưng việc truy tìm ở cấp agent đòi hỏi phải xây dựng phần mềm bổ sung. Amazon Bedrock AgentCore Observability (bản xem trước) được công bố gần đây hỗ trợ OpenTelemetry để tích hợp dữ liệu đo từ xa của agent với các dịch vụ quan sát hiện có, bao gồm CloudWatch, Datadog, LangSmith và Langfuse. Để biết thêm chi tiết về các tính năng của Amazon Bedrock AgentCore Observability, hãy xem Ra mắt khả năng quan sát AI tạo sinh của Amazon CloudWatch (Bản xem trước).\nNgoài việc giám sát, việc kiểm tra và xác thực các agent cũng vượt ra ngoài các phương pháp phần mềm thông thường. Các bộ kiểm tra tự động như promptfoo giúp các nhóm phát triển định cấu hình các bài kiểm tra để đánh giá chất lượng suy luận, hoàn thành nhiệm vụ và sự mạch lạc của cuộc đối thoại. Các kiểm tra trước khi triển khai xác nhận kết nối công cụ và quyền truy cập kiến ​​thức, và việc tiêm lỗi mô phỏng tình trạng ngừng hoạt động của công cụ, lỗi API và sự không nhất quán của dữ liệu để phát hiện ra các sai sót trong suy luận trước khi chúng ảnh hưởng đến người dùng.\nKhi sự cố phát sinh, việc giảm thiểu dựa vào các playbook bao gồm cả các vấn đề ở cấp cơ sở hạ tầng và dành riêng cho agent. Các playbook này hỗ trợ các phiên trực tiếp, cho phép chuyển giao liền mạch cho các agent dự phòng hoặc người vận hành mà không làm mất ngữ cảnh.\nTóm tắt Trong bài viết này, chúng tôi đã giới thiệu mô hình kiến trúc gồm bảy khía cạnh để lập bản đồ cho các tác nhân AI của bạn và phân tích nơi các rủi ro về khả năng phục hồi có thể phát sinh. Chúng tôi cũng đã xác định năm dạng lỗi phổ biến liên quan đến các tác nhân AI cùng với các chiến lược giảm thiểu tương ứng.\nCác chiến lược này minh họa cách các nguyên tắc về khả năng phục hồi được áp dụng cho các khối lượng công việc tác nhân thường gặp, nhưng chúng không phải là toàn diện. Mỗi hệ thống AI đều có những đặc điểm và sự phụ thuộc riêng. Bạn cần phân tích kiến trúc cụ thể của mình dựa trên bảy khía cạnh rủi ro để xác định những thách thức về khả năng phục hồi trong khối lượng công việc của riêng bạn, đồng thời ưu tiên các khu vực dựa trên mức độ ảnh hưởng đến người dùng và tầm quan trọng với doanh nghiệp thay vì độ phức tạp kỹ thuật.\nKhả năng phục hồi là một hành trình liên tục chứ không phải một điểm đến. Khi các tác nhân AI của bạn phát triển và xử lý những trường hợp sử dụng mới, các chiến lược về khả năng phục hồi của bạn cũng phải tiến hóa theo. Bạn có thể thiết lập quy trình kiểm thử, giám sát và cải tiến thường xuyên để đảm bảo các hệ thống AI của bạn luôn duy trì khả năng phục hồi khi mở rộng quy mô. Để biết thêm thông tin về các tác nhân AI tạo sinh và khả năng phục hồi trên AWS, hãy tham khảo các tài nguyên sau:\nChaos Engineering Scenarios for GenAI workloads Designing generative AI workloads for resilience Introducing Amazon Bedrock AgentCore: Securely deploy and operate AI agents at any scale (preview) Implement effective data authorization mechanisms to secure your data used in generative AI applications: Part 1 and Part 2 Yiwen Zhang Yiwen Zhang là Kiến trúc sư Giải pháp GenAI cấp cao tại AWS. Cô phát triển cả các ứng dụng generative AI và chiến lược tích hợp doanh nghiệp. Với bằng Tiến sĩ về thống kê tính toán và hơn một thập niên kinh nghiệm trong phát triển và triển khai AI/ML và các pipeline dữ liệu, cô mang đến chuyên môn sâu cho chuyển đổi AI doanh nghiệp. Cô tập trung vào việc biến generative AI trở nên thực tế bằng cách xây dựng các MVP AI có hiệu quả và xử lý các vấn đề khó như ROI, tinh chỉnh hiệu năng agent AI, quản lý chi phí, bảo mật và độ bền sản xuất. Mục tiêu của cô là giúp các doanh nghiệp biến agent generative AI thành các giải pháp “kết quả như một dịch vụ”.\rHechmi Khelifi Hechmi Khelifi là Kiến trúc sư Giải pháp Doanh nghiệp tại AWS, chuyên về tính bền vững và độ tin cậy. Với hơn 3 năm làm việc tại AWS và bằng Tiến sĩ từ Đại học Québec, Hechmi tận dụng kinh nghiệm CNTT rộng và nền tảng học thuật để giúp khách hàng xây dựng các giải pháp vững chắc và có khả năng chịu lỗi.\rJennifer Moran Jennifer Moran là Kiến trúc sư Giải pháp Chuyên gia về Resilience cao cấp tại AWS. Cô mang đến kinh nghiệm đa dạng từ nhiều vai trò kỹ thuật trong ngành phần mềm. Chuyên môn của cô tập trung vào việc thiết kế các giải pháp có độ bền cao để cải thiện “posture” độ bền tổng thể của hệ thống.\r"
},
{
	"uri": "//localhost:1313/vi/3-translatedblog/blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Mở rộng liền mạch các job EDA lên AWS bằng giải pháp Synopsys Cloud Hybrid Bài viết này được đóng góp bởi Varun Shah, Xingang Zhao (Synopsys), Dnyanesh Digraskar, Mayur Runwal (AWS)\nTrong bài viết này, chúng tôi mô tả cách khách hàng có thể mở rộng (burst) khối lượng công việc Synopsys của họ lên AWS bằng giải pháp Synopsys Cloud Hybrid. Giải pháp này đơn giản hóa quy trình làm việc bằng cách loại bỏ nhu cầu phải di chuyển dữ liệu thủ công giữa lưu trữ tại chỗ (on-premises storage) và cloud. Dữ liệu cần thiết cho một job chạy trên AWS sẽ được cache dần dần ở chế độ nền và sẵn sàng cho tiến trình. Tương tự, khi cần, dữ liệu chọn lọc được ghi bởi một job đang chạy trên cloud có thể được đẩy về hệ thống tại chỗ theo thời gian thực – giúp cho lưu trữ tại chỗ luôn được cập nhật.\nNgành công nghiệp bán dẫn đang chứng kiến sự tăng trưởng bùng nổ, được thúc đẩy bởi trí tuệ nhân tạo (AI), điện toán hiệu năng cao (HPC – High Performance Computing), và sự phổ biến của các hệ thống thông minh. Các kỹ sư đang đối mặt với mức độ phức tạp chưa từng có cùng tốc độ đổi mới ngày càng nhanh. Khi chip ngày càng mạnh mẽ và tinh vi hơn, vòng đời thiết kế trở nên dài hơn, chi phí tăng cao, và nguy cơ bỏ lỡ thời điểm tung sản phẩm ra thị trường (time to market) cũng lớn hơn. Trong bối cảnh này, “time to market” đã trở thành yếu tố khác biệt mang tính quyết định.\nHạ tầng dựa trên cloud mang lại khả năng mở rộng và linh hoạt để gia tăng quy mô hoạt động thiết kế chip và đáp ứng nhu cầu khách hàng. AWS cung cấp quyền truy cập dễ dàng vào tài nguyên tính toán trên cloud được tối ưu cho khối lượng công việc EDA. Amazon Elastic Compute Cloud (Amazon EC2) mang đến khả năng truy cập vào thế hệ bộ xử lý mới nhất với dung lượng gần như không giới hạn, có thể triển khai trên toàn cầu. Các instance thế hệ mới dựa trên x86 và ARM trên AWS giúp đạt hiệu suất tối đa và cho phép khách hàng khai thác tối đa license phần mềm EDA của mình.\nSynopsys là một AWS Partner, cung cấp giải pháp thiết kế toàn diện và đáng tin cậy từ silicon đến hệ thống cho khách hàng, bao gồm từ EDA đến silicon IP cũng như xác minh và thẩm định hệ thống (system verification and validation).\nTrong bài viết này, chúng tôi sẽ minh họa việc kiểm thử khả năng mở rộng (scale-testing) một tập hợp công cụ EDA của Synopsys trên AWS và mô tả hiệu năng, chất lượng kết quả cũng như thời gian hoàn thành.\nGiải pháp Synopsys Cloud Hybrid: mở rộng các job EDA lên AWS AWS giúp việc thiết lập hạ tầng tính toán trên cloud trở nên dễ dàng nhờ vào danh mục phần cứng và dịch vụ phong phú dành cho các luồng công việc trong ngành bán dẫn và công nghệ cao. Các công ty có thể điều chỉnh nhu cầu tính toán của mình phù hợp với các workflow quan trọng về thời gian. Ở mức tổng quan, các bước để mở rộng (burst) khối lượng công việc EDA trên AWS bao gồm:\nXác định các khối thiết kế (design blocks)/job cần được chạy trên cloud Truyền dữ liệu liên quan lên cloud Cài đặt các binary ứng dụng EDA và license trên cloud Chạy các job EDA Truyền kết quả trở lại hệ thống tại chỗ (on-premises) để phân tích/khắc lỗi (debug)/tạo báo cáo Hai bước đầu tiên (1 \u0026amp; 2) ở trên có thể gây tốn công, bởi việc đóng gói đúng tập hợp file, mã nguồn, thư viện, dependencies, script, v.v… có thể mất đến vài tuần. Synopsys Cloud Hybrid Solution cung cấp một cơ chế kích hoạt trên cloud giúp thực hiện các tác vụ này dễ dàng hơn.\nKiến trúc và các thành phần Hình 1: Sơ đồ kiến trúc của giải pháp Synopsys Cloud Hybrid với AWS được sử dụng cho thử nghiệm được mô tả trong blog này\nHình 1 minh họa kiến trúc tổng thể của giải pháp Synopsys Cloud Hybrid. Các thành phần kiến trúc chính bao gồm:\nOn-premises storage: Đây là các điểm mount NFS với dữ liệu thiết kế, cần được cung cấp cho các compute node trên AWS. Giải pháp hybrid này hoạt động với bất kỳ giải pháp lưu trữ từ bên thứ ba hoặc ISV thương mại nào.\nScheduler: Giải pháp Hybrid hoạt động với bất kỳ job scheduler thương mại nào, như AWS Parallel Computing Service (PCS), AWS ParallelCluster, AWS Batch, hoặc IBM LSF, UGE, Slurm, v.v… Sơ đồ kiến trúc minh họa việc sử dụng IBM LSF multi-cluster tích hợp với LSF resource connector để cung cấp tài nguyên trên AWS.\nCompute farms:\nOn-premises: Trung tâm dữ liệu (datacenter) với sự kết hợp của nhiều loại máy chủ tính toán khác nhau. Trên AWS: Các Amazon EC2 instance được sử dụng để chạy mô phỏng EDA. Trong thử nghiệm này, chúng tôi sử dụng instance loại 16xlarge với CPU 3.5GHz, 8GB bộ nhớ cho mỗi vCPU. Nhiều loại EC2 instance khác có thể được dùng tùy theo ứng dụng và thiết kế bán dẫn cụ thể. On Cloud NFS: Với các job EDA ghi dữ liệu trung gian không cần thiết trên hệ thống tại chỗ, một Amazon FSx for NetApp ONTAP filesystem đã được cung cấp để compute resources trên AWS sử dụng.\nSynopsys Cloud Hybrid Solution: Người dùng cài đặt binary này trên Amazon EC2 instance và cấu hình data-sync để xử lý việc di chuyển dữ liệu giữa on-prem và AWS.\nLicensing:\nLicenses cho ứng dụng EDA: Các license ứng dụng EDA hiện có và license server tiếp tục cấp license cho các job chạy trên AWS. Các nhu cầu license bổ sung có thể được đáp ứng bằng Synopsys FlexEDA và Pay-Per-Use metered licensing. License cho Hybrid solution: Đây là một ứng dụng riêng biệt mà người dùng cần mua từ Synopsys. License được cung cấp từ hệ thống network license server do Synopsys quản lý. Thiết lập Synopsys Cloud Hybrid Solution Việc thiết lập bao gồm 3 thành phần chính:\nHybrid Cloud data-sync: Bao gồm cài đặt Hybrid solution trên một loại instance được khuyến nghị trên AWS, cấu hình mạng để cho phép lưu lượng giữa on-premises và AWS cho license (của Hybrid Cloud solution), lưu trữ dữ liệu và xử lý phân tán, xác định các mount lưu trữ NFS tại chỗ cần ánh xạ, và khởi chạy Hybrid solution để thiết lập data-sync mapping. Network Connectivity: Các kết nối mạng chuyên dụng như AWS DirectConnect cung cấp băng thông cao hơn, độ trễ thấp hơn, rất phù hợp để xử lý khối lượng công việc với lượng dữ liệu lớn. Ngoài ra, có thể dùng đường hầm VPN IPsec với AWS, nhưng tốc độ và độ tin cậy kém hơn so với kết nối chuyên dụng. Scheduler setup: Phụ thuộc vào từng scheduler cụ thể. Ví dụ, với IBM LSF, điều này bao gồm việc triển khai LSF multi-cluster, định nghĩa các cluster tham gia, cấu hình queue và xác minh rằng cluster trên AWS có thể được cung cấp động theo nhu cầu. Thông tin chung về nền tảng Với , dữ liệu được chọn lọc được ghi bởi một tác vụ chạy trên đám mây có thể được ghi ngược trở lại hệ thống on-premises theo thời gian thực, giúp kho lưu trữ tại chỗ luôn được cập nhật. Lưu ý rằng việc ghi dữ liệu ngược lại sẽ phát sinh phí truyền dữ liệu ra khỏi AWS. Dữ liệu đầu ra tạm thời từ các tác vụ đang chạy không cần thiết cho on-prem hoặc dữ liệu đầu ra lớn, lưu trữ lâu dài có thể được chuyển hướng đến NFS trên đám mây. Nếu cần, dữ liệu này có thể được lập trình để ghi ngược lại sau khi tác vụ hoàn tất.\nBộ lập lịch tác vụ nên được cung cấp bởi khách hàng. Sau đó, nó sẽ tìm tài nguyên tính toán phù hợp, tại chỗ hoặc trên AWS, và Giải pháp Lai sẽ xử lý việc di chuyển dữ liệu cần thiết. Giải pháp Synopsys Cloud Hybrid có khả năng cấu hình bộ lập lịch để tự động sử dụng hết công suất tính toán tại chỗ trước, sau đó lập lịch các tác vụ trên các nút tính toán đám mây, hoặc chạy tất cả tác vụ trên các nút đám mây tùy thuộc vào ứng dụng đang chạy và kích thước/tần suất dữ liệu được chia sẻ giữa các tiến trình khác nhau của ứng dụng.\nKiểm thử khả năng mở rộng giải pháp Synopsys Hybrid trên AWS Các job EDA có thể rất nặng về dữ liệu, cả ở đầu vào và đầu ra. Độ trễ của mạng và lượng dữ liệu di chuyển qua lại có thể ảnh hưởng đến hiệu năng của job EDA. Để hiểu rõ giới hạn của Synopsys Hybrid Solution, chúng tôi đã sử dụng sáu ứng dụng chủ lực (flagship applications) của Synopsys vốn rất quan trọng trong quy trình thiết kế mỗi chip bán dẫn. Bao gồm:\nPrimeLib – ứng dụng đặc tả và thẩm định thư viện Synopsys VCS – Trình mô phỏng để xác minh thiết kế bán dẫn PrimeSim SPICE – Trình mô phỏng SPICE tăng tốc bằng GPU cho thiết kế Analog, RF, và Mixed-signal Synopsys PrimeWave – ứng dụng cho việc thiết lập mô phỏng và phân tích thiết kế Analog, RF, Mixed-signal, custom-digital và thiết kế bộ nhớ PrimeTime – ứng dụng phân tích định thời tĩnh với khả năng tính toán hiệu quả về bộ nhớ, hỗ trợ scalar và đa nhân Synopsys DSO.ai – ứng dụng tối ưu không gian thiết kế được hỗ trợ bởi AI Tất cả các ứng dụng EDA này có đặc điểm khác nhau về pattern I/O, lượng dữ liệu sinh ra (kích thước và số lượng file), cũng như lượng và tần suất giao tiếp giữa các worker của một job. Mỗi ứng dụng được thực thi bằng Synopsys Cloud Hybrid Solution với các thiết kế và testcase chuẩn. Chúng tôi ưu tiên các job yêu cầu IOPs cao khi chọn testcase cho bài đo chuẩn.\nChúng tôi theo dõi nhiều chỉ số và so sánh chúng giữa các thử nghiệm thực hiện trên Synopsys Cloud Solution với AWS và trên hạ tầng on-premises tương đương:\nHiệu năng: Thời gian chạy là chỉ số then chốt vì nó trực tiếp tác động đến “time to market”. Chất lượng kết quả (QoR): QoR là một chỉ số quan trọng khác, không thể bị ảnh hưởng. Các ứng dụng phân tích kết quả về coverage, bài kiểm thử pass/fail, các regression và đưa ra cách diễn giải về chất lượng tổng thể của kết quả. Với các ứng dụng được thử nghiệm, chúng tôi kỳ vọng sẽ có kết quả QoR giống hoặc tương tự giữa AWS và on-premises. Thời gian thiết lập: Nếu hiệu năng và QoR tương đương, điểm làm cho Synopsys Cloud Hybrid Solution trở nên đáng giá chính là thời gian có thể tiết kiệm được trong việc di chuyển dữ liệu liên quan lên cloud để sử dụng hạ tầng tính toán của AWS. Dù khó đo lường với hệ thống on-premises và khác nhau đáng kể giữa các EDA flow, chúng tôi đã cố gắng ước lượng. Kết quả Hiệu suất Table 1: Bảng 1: Hiệu năng của các ứng dụng Synopsys chạy trên Hybrid Solution với AWS so với on-premises\nChúng tôi chạy bộ kiểm thử baseline này trên on-premises hoặc trên AWS tùy theo tình trạng sẵn có của tài nguyên tại chỗ. Bảng 1 cho thấy hiệu năng tổng thể của tất cả các EDA flow được thử nghiệm bằng Synopsys Cloud Hybrid Solution là tương đương – hoặc trong một số trường hợp còn tốt hơn – so với baseline. Với Hybrid Setup, thời gian chạy bao gồm cả thời gian ghi dữ liệu đầu ra cuối cùng trở lại lưu trữ on-premises thông qua Hybrid Solution. Điều này làm hiệu năng tổng thể bị ảnh hưởng nhẹ khi so với việc chạy baseline trực tiếp trên cloud, như trong trường hợp PrimeLib và VCS. Dữ liệu cũng cho thấy hiệu năng tốt hơn so với baseline chạy on-premises đối với PrimeTime và PrimeSim, nhờ có sẵn CPU nhanh hơn trên AWS.\nThông qua việc phân tích IO pattern (kích thước, tần suất) của các ứng dụng EDA khác nhau, chúng tôi đã xác định một số best practices để thiết lập các ứng dụng này nhằm tận dụng tối đa Hybrid Solution.\nChất lượng kết quả (QoR) Như dự đoán, không có sự suy giảm về chất lượng kết quả, PPA hay coverage khi sử dụng Hybrid Solution. Với các ứng dụng EDA như VCS, PrimeSim, kết quả khớp hoàn toàn với các lần chạy on-premises. Với các ứng dụng khác như DSO.ai, các báo cáo, PPA và QoR đều tương đương.\nThời gian thiết lập: Synopsys Hybrid Cloud tiết kiệm tới vài tuần thiết lập cho mỗi dự án nhờ tự động hóa việc di chuyển dữ liệu thủ công và xác minh các design block. Ví dụ, từ thử nghiệm nội bộ của chúng tôi với QA regressions của một ứng dụng EDA, khoảng 4 tuần công sức thủ công đã được tiết kiệm nhờ Hybrid Solution loại bỏ nhu cầu \u0026ldquo;lift and shift\u0026rdquo; các workload EDA.\nTùy theo workflow, Synopsys có thể hỗ trợ đưa ra khuyến nghị best practices ở chế độ cloud-native hoặc burst mode với Synopsys Cloud Hybrid Solution. Ở chế độ burst mode đúng nghĩa, dữ liệu sẽ được ghi vào on-cloud NFS, sau đó dữ liệu chọn lọc được đồng bộ ngược lại on-premises sau khi job hoàn tất. Cách này giúp giảm thiểu chi phí data egress và ảnh hưởng đến hiệu năng. Burst mode mang lại giá trị lớn bằng cách di chuyển dần dần dữ liệu đầu vào cần thiết lên cloud để chạy job thông qua Hybrid Solution.\nKết luận EDA workload đòi hỏi sức mạnh tính toán khổng lồ và khả năng truy cập dữ liệu liền mạch. Khối lượng dữ liệu thiết kế rất lớn, kết hợp với tính lặp đi lặp lại và mức độ phụ thuộc cao của các tác vụ EDA, khiến việc di chuyển dữ liệu liên tục giữa lưu trữ on-premises và compute trên cloud có thể trở nên chậm và kém hiệu quả.\nSynopsys Cloud Hybrid Solution giải quyết vấn đề này bằng cách cung cấp phương thức liền mạch để burst các job EDA từ on-premises lên cloud với cơ chế đồng bộ dữ liệu hai chiều theo thời gian thực. Sản phẩm đã được kiểm thử tải nặng (stress-tested) với sáu ứng dụng EDA chủ lực của Synopsys. Chúng tôi nhận thấy hiệu năng của các ứng dụng ở chế độ Hybrid là tương đương với việc chạy on-premises hoặc cloud-native, đồng thời vẫn giữ nguyên chất lượng kết quả (QoR). Việc di chuyển dữ liệu được xử lý một cách “vô hình” bởi Synopsys Cloud Hybrid Solution, giúp tiết kiệm tới nhiều tuần thiết lập.\nVarun Shah Varun Shah làm việc trong nhóm quản lý sản phẩm cho Synopsys Cloud, chịu trách nhiệm về lộ trình công nghệ, tích hợp phần mềm EDA với nền tảng đám mây và phân tích phản hồi từ khách hàng. Ông có bằng Thạc sĩ Kỹ thuật Điện từ Đại học Missouri-Rolla và là chuyên gia quản lý sản phẩm được chứng nhận từ Trường Quản lý Kellogg.\rDnyanesh Digraskar Dnyanesh Digraskar là Kiến trúc sư Giải pháp Chủ chốt (Principal HPC Partner Solutions Architect) tại AWS. Ông dẫn dắt chiến lược triển khai HPC với các đối tác ISV để giúp họ xây dựng giải pháp theo kiến trúc tốt, có thể mở rộng. Ông có hơn 15 năm kinh nghiệm trong lĩnh vực CFD, CAE, mô phỏng số học và khoa học hiệu năng cao (HPC). Ông tốt nghiệp Thạc sĩ Kỹ thuật Cơ khí tại Đại học Massachusetts, Amherst.\rMayur Runwal Mayur Runwal là Kiến trúc sư Giải pháp cao cấp tại AWS, chuyên về tự động hóa thiết kế điện tử (EDA). Ông thiết kế các luồng công việc thiết kế và xác minh chip cho khách hàng AWS. Trước khi gia nhập AWS, ông đã lãnh đạo các nhóm hạ tầng CNTT tại các công ty bán dẫn trong 10 năm, với kinh nghiệm bao gồm thiết kế và triển khai giải pháp máy tính hiệu năng cao cũng như hạ tầng doanh nghiệp.\rXingang Zhao Xingang Zhao là Quản lý Sản phẩm Kỹ thuật (Technical Product Manager) cho Synopsys Cloud. Anh chịu trách nhiệm đánh giá kỹ thuật và tích hợp các dịch vụ/ công cụ đám mây mới lên các nền tảng công cộng nhằm tăng hiệu năng và tiết kiệm chi phí cho các khối công việc EDA. Anh có bằng Cử nhân Kỹ thuật Điện từ Đại học Zhejiang và được chứng nhận quản lý sản phẩm tại Trường Kellogg.\r"
},
{
	"uri": "//localhost:1313/vi/2-proposal/2.1-createec2/",
	"title": "Chuẩn bị VPC và EC2",
	"tags": [],
	"description": "",
	"content": "Trong bước này, chúng ta sẽ cần tạo một VPC có 2 subnet public / private. Sau đó tạo 1 EC2 Instance Linux nằm trong public subnet, 1 EC2 Instance Windows nằm trong private subnet.\nTổng quan kiến trúc sau khi các bạn hoàn tất bước này sẽ như sau:\nĐể tìm hiểu cách tạo các EC2 instance và VPC với public/private subnet các bạn có thể tham khảo bài lab :\nGiới thiệu về Amazon EC2 Làm việc với Amazon VPC Nội dung Tạo VPC Tạo Public subnet Tạo Private subnet Tạo security group Tạo máy chủ Linux public Tạo máy chủ Windows private "
},
{
	"uri": "//localhost:1313/vi/4-events/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Báo cáo tổng hợp: “Hội thảo Dịch vụ AWS AI/ML \u0026amp; Generative AI” Mục tiêu Sự kiện Cung cấp cái nhìn tổng quan về bức tranh AI/ML tại Việt Nam. Minh họa quy trình máy học (Machine Learning) toàn diện sử dụng Amazon SageMaker. Giới thiệu các khả năng của Generative AI với Amazon Bedrock (Mô hình nền tảng, Agents, Guardrails). Chia sẻ các kỹ thuật về Kỹ thuật tạo câu lệnh (Prompt Engineering) và Tạo nội dung tăng cường truy xuất (RAG). Diễn giả Các Kiến trúc sư giải pháp (Solutions Architects) Các Chuyên gia về AI/ML Điểm nhấn Chính Tổng quan Dịch vụ AWS AI/ML (SageMaker) Nền tảng Toàn diện: Bao phủ toàn bộ vòng đời từ chuẩn bị dữ liệu đến triển khai. Chuẩn bị dữ liệu: Các chiến lược gán nhãn và làm sạch dữ liệu. Huấn luyện \u0026amp; Tinh chỉnh: Tối ưu hóa mô hình về hiệu năng và chi phí. Triển khai: Đưa mô hình lên môi trường production (thực tế) một cách hiệu quả. MLOps Tích hợp: Nêu bật khả năng tự động hóa và chuẩn hóa các đường ống (pipeline) ML. SageMaker Studio: Demo trực tiếp giao diện thống nhất để xây dựng, huấn luyện và triển khai mô hình. Generative AI với Amazon Bedrock Mô hình Nền tảng (FMs): Hướng dẫn so sánh và lựa chọn các mô hình hàng đầu: Claude: Khả năng suy luận cao. Llama: Mã nguồn mở và hiệu quả. Titan: Tích hợp nguyên bản (native) với AWS. Prompt Engineering (Kỹ thuật Prompt): Chain-of-Thought (Chuỗi suy luận): Chia nhỏ các tác vụ suy luận phức tạp. Few-shot learning (Học từ vài mẫu): Sử dụng các ví dụ mẫu để cải thiện kết quả đầu ra. Kiến trúc Nâng cao: RAG (Retrieval-Augmented Generation): Tích hợp Knowledge Bases (Cơ sở tri thức) để căn cứ câu trả lời dựa trên dữ liệu doanh nghiệp. Bedrock Agents: Tạo quy trình làm việc đa bước và tích hợp với các công cụ bên ngoài. Guardrails (Bộ lọc an toàn): Đảm bảo an toàn và lọc nội dung. Bài học Chính (Key Takeaways) Tư duy Thiết kế Lựa chọn Mô hình: Chọn Mô hình nền tảng phù hợp (ví dụ: Claude vs. Titan) dựa trên yêu cầu cụ thể của trường hợp sử dụng (tốc độ vs. khả năng suy luận). An toàn là trên hết: Việc triển khai Guardrails là rất quan trọng đối với ứng dụng AI có trách nhiệm trong môi trường doanh nghiệp. Kiến trúc Kỹ thuật Ưu tiên RAG hơn Fine-tuning: Đối với hầu hết các trường hợp sử dụng kiến thức nội bộ, RAG mang lại giải pháp linh hoạt và tiết kiệm chi phí hơn so với việc tinh chỉnh mô hình. Quy trình làm việc Agentic: Chuyển từ chatbot thụ động sang các Agent chủ động có thể thực thi tác vụ là biên giới tiếp theo của GenAI. Chiến lược Hiện đại hóa Áp dụng MLOps: Chuyển từ huấn luyện mô hình thủ công sang các pipeline tự động (MLOps) là điều cần thiết để mở rộng quy mô. Bối cảnh Địa phương: Hiểu rõ các xu hướng AI/ML cụ thể tại Việt Nam giúp đối chiếu tiêu chuẩn cho các dự án trong nước. Ứng dụng vào Công việc Thử nghiệm SageMaker: Đánh giá quy trình ML hiện tại và xác định cơ hội chuyển đổi sang Amazon SageMaker để quản lý vòng đời tốt hơn. Xây dựng Bot Kiến thức: Tạo nguyên mẫu sử dụng Amazon Bedrock và RAG để tra cứu tài liệu nội bộ hoặc hướng dẫn kỹ thuật. Cải thiện Prompt: Áp dụng ngay kỹ thuật Chain-of-Thought và Few-shot để nâng cao độ chính xác của các tương tác AI hiện tại. Triển khai Guardrails: Cấu hình bộ lọc nội dung trên Bedrock để đảm bảo an toàn thương hiệu cho các ứng dụng thử nghiệm. Trải nghiệm Sự kiện Tham dự hội thảo “AWS AI/ML Services \u0026amp; Generative AI” đã cung cấp một lộ trình thực tế để áp dụng các dịch vụ thông minh. Những trải nghiệm chính bao gồm:\nHọc hỏi từ chuyên gia Hiểu rõ hơn về bức tranh AI/ML tại Việt Nam, nắm bắt các cơ hội và thách thức tại địa phương. Đào sâu kiến thức kỹ thuật về sự khác biệt giữa các Mô hình nền tảng lớn (Claude, Llama, Titan). Tiếp cận kỹ thuật thực tế Phần hướng dẫn SageMaker Studio đã minh họa cách thống nhất chuỗi công cụ ML rời rạc vào một giao diện quản lý duy nhất. Demo trực tiếp về Bedrock đã cho thấy việc triển khai thực tế một chatbot GenAI, giải mã sự phức tạp của RAG và Agents. Kết nối và thảo luận Hoạt động ice-breaker và các phiên networking cho phép trao đổi ý tưởng với đồng nghiệp về những thách thức thực tế khi triển khai GenAI. Các cuộc thảo luận củng cố tầm quan trọng của Prompt Engineering như một kỹ năng quan trọng cho phát triển hiện đại. Bài học rút ra RAG là chìa khóa để làm cho LLM hữu ích với dữ liệu đặc thù của doanh nghiệp mà không tốn chi phí huấn luyện cao. Guardrails không phải là tùy chọn; chúng là một lớp nền tảng của ngăn xếp (stack) Generative AI. Hiệu quả trong ML đến từ MLOps tích hợp thay vì các thử nghiệm khoa học dữ liệu riêng lẻ. Ảnh sự kiện "
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Session Management",
	"tags": [],
	"description": "",
	"content": "\rBáo cáo Thực tập Thông tin Sinh viên Họ và tên: Lương Nguyễn Duy Khang\nSố điện thoại: 0931984914\nEmail: lndkhang278@gmail.com\nTrường đại học: FPT University\nChuyên ngành: Software Engineer\nLớp:\nCông ty thực tập: Amazon Web Services Vietnam Co., Ltd.\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: From 12/08/2025 to 12/11/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "//localhost:1313/vi/2-proposal/2.1-createec2/2.1.1-createvpc/",
	"title": "Tạo VPC ",
	"tags": [],
	"description": "",
	"content": "Tạo VPC Lab VPC Truy cập giao diện quản trị dịch vụ VPC Click Your VPC. Click Create VPC. Tại trang Create VPC. Tại mục Name tag điền Lab VPC. Tại mục IPv4 CIDR điền : 10.10.0.0/16. Click Create VPC. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week1/",
	"title": "TUẦN 1",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu tuần 1: Kết nối và lập nhóm với các sinh viên tại FCJ Đề xuất ý tưởng cho dự án cuối kỳ Học tập và làm các bài lab trên website FCJ Hiểu các khái niệm cơ bản về điện toán đám mây và dịch vụ AWS Nhiệm vụ đã thực hiện trong tuần Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Làm quen và ghi chú các nhiệm vụ First Cloud Journey dành cho sinh viên, nội quy và tài liệu học tập 09/08/2025 09/08/2025 3 - Tự học về điện toán đám mây - Khám phá các dịch vụ AWS 09/09/2025 09/09/2025 Liên kết 4 - Tạo tài khoản AWS Free Tier - Học cách quản lý chi phí với AWS Budgets Thực hiện: + Tạo tài khoản AWS + Tạo các loại ngân sách khác nhau 09/10/2025 09/10/2025 Liên kết 5 - Học về EC2 - Các phương thức kết nối SSH tới EC2 - Tìm hiểu Elastic IP - Đề xuất ý tưởng cho dự án cuối kỳ - Học về VPC 09/11/2025 09/11/2025 Liên kết 6 Thực hiện: + Tạo security groups + Tạo subnets + Khởi chạy một EC2 instance + Kết nối qua SSH + Gắn thêm một EBS volume - Tham gia họp và chọn một ý tưởng cho dự án cuối kỳ 09/12/2025 09/12/2025 Liên kết Thành tựu tuần 1 Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nTính toán (Compute) Lưu trữ (Storage) Mạng (Networking) Cơ sở dữ liệu (Database) Tạo và cấu hình thành công tài khoản AWS Free Tier.\nLàm quen với AWS Management Console và học cách tìm, truy cập, sử dụng các dịch vụ qua giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính, bao gồm:\nAccess Key Secret Key Khu vực mặc định (Default Region) Khám phá các dịch vụ AWS thông qua tự học và tài liệu để hiểu cách sử dụng.\nHọc cách quản lý chi phí hiệu quả với AWS Budgets, bao gồm tạo nhiều loại ngân sách khác nhau.\nTrải nghiệm thực hành với EC2: tìm hiểu tính năng, phương thức kết nối (SSH) và Elastic IP.\nHọc các kiến thức cơ bản về VPC và thiết lập mạng trong AWS.\nThực hành tạo security groups, subnets và khởi chạy một EC2 instance.\nKết nối thành công tới EC2 qua SSH và gắn thêm một EBS volume.\nLàm việc nhóm để đề xuất và chọn một ý tưởng cho dự án cuối kỳ.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/week2/",
	"title": "Tuần 2",
	"tags": [],
	"description": "",
	"content": "Nhật ký CÔNG VIỆC Mục tiêu tuần 2 Học và thực hành các dịch vụ lưu trữ và cơ sở dữ liệu của AWS (Amazon S3, Amazon RDS). Làm quen và tự học Spring Boot để chuẩn bị cho phát triển backend. Nắm bắt kiến thức về giám sát hệ thống với Amazon CloudWatch. Học và thực hành triển khai với Amazon Lightsail và Lightsail Container. Tiếp tục tự học PostgreSQL để tích hợp với Spring Boot. Tìm hiểu cơ chế mở rộng tài nguyên với Amazon EC2 Auto Scaling. Công việc đã thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học Amazon S3 và Amazon RDS\n- Thực hiện: labs Amazon S3, labs Amazon RDS\n- Tự học Spring Boot 15/09/2025 15/09/2025 AWS Study Group 3 - Tự học Spring Boot\n- Học Amazon CloudWatch 16/09/2025 16/09/2025 AWS Study Group 4 - Tự học Spring Boot và PostgreSQL\n- Thực hiện: labs Amazon CloudWatch 17/09/2025 17/09/2025 AWS Study Group 5 - Tự học Spring Boot và PostgreSQL\n- Học Amazon Lightsail và Lightsail Container\n- Thực hiện: labs Lightsail, labs Lightsail Container 18/09/2025 18/09/2025 AWS Study Group 6 - Tự học Spring Boot và PostgreSQL\n- Học Amazon EC2 Auto Scaling 19/09/2025 19/09/2025 AWS Study Group Thành tựu tuần 2 Hoàn thành labs Amazon S3, nắm được cách tạo bucket, upload/download và quản lý quyền truy cập. Hoàn thành labs Amazon RDS, tạo cơ sở dữ liệu, kết nối và quản lý dữ liệu. Tự học và nắm kiến thức cơ bản về Spring Boot (cấu trúc dự án, dependency, tạo API cơ bản). Học về Amazon CloudWatch và thực hành labs để thiết lập giám sát, metric và cảnh báo. Tìm hiểu PostgreSQL và nắm cách tích hợp cơ bản với Spring Boot. Hoàn thành labs Amazon Lightsail và Lightsail Container, triển khai ứng dụng mẫu và quản lý container. Hiểu cơ chế Amazon EC2 Auto Scaling và cách tự động tăng giảm số lượng instance theo nhu cầu. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week3/",
	"title": "Tuần 3",
	"tags": [],
	"description": "",
	"content": "Nhật ký CÔNG VIỆC Mục tiêu tuần 3 Thiết lập dự án cơ bản cho phát triển backend. Học và thực hành Amazon Route 53. Tiếp tục học về Amazon EC2 Auto Scaling. Phát triển các tính năng xác thực cốt lõi: đăng ký, đăng nhập và JWT services. Học và thực hành với Amazon CLI. Hợp tác cùng nhóm để xem xét tiến độ dự án. Công việc đã thực hiện trong tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Thiết lập dự án cơ bản cho phát triển\n- Học về Amazon Route 53\n- Thực hiện: labs Amazon EC2 Auto Scaling 22/09/2025 22/09/2025 AWS Study Group 3 - Bắt đầu phát triển tính năng đăng ký\n- Thực hiện: labs Amazon Route 53 23/09/2025 23/09/2025 AWS Study Group 4 - Tiếp tục phát triển tính năng đăng ký\n- Học về Amazon CLI 24/09/2025 24/09/2025 AWS Study Group 5 - Họp nhóm về tiến độ dự án\n- Hoàn thành đăng ký và bắt đầu phát triển đăng nhập cùng JWT services 25/09/2025 25/09/2025 AWS Study Group 6 - Hoàn thiện đăng nhập và JWT services\n- Thực hiện: labs Amazon CLI 26/09/2025 26/09/2025 AWS Study Group Thành tựu tuần 3 Thiết lập thành công cấu trúc dự án cơ bản cho phát triển. Hoàn thành labs về Amazon EC2 Auto Scaling và Amazon Route 53, nắm kiến thức về mở rộng và quản lý DNS. Triển khai tính năng đăng ký người dùng và sau đó mở rộng với đăng nhập và xác thực dựa trên JWT. Thực hành sử dụng Amazon CLI và hoàn thành các labs liên quan. Tổ chức họp nhóm để thảo luận tiến độ dự án và phân công công việc. Hoàn thành luồng xác thực cốt lõi (đăng ký + đăng nhập + JWT services), tạo nền tảng cho phát triển backend an toàn. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week4/",
	"title": "Tuần 4",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu tuần 4 Sửa lỗi và tối ưu các tính năng xác thực người dùng (đăng ký/đăng nhập). Tìm hiểu và tích hợp cổng thanh toán MoMo vào dự án. Tham gia các buổi họp nhóm để đánh giá tiến độ và thảo luận về đề xuất dự án. Học và thực hành với Amazon DynamoDB. Tìm hiểu cách sử dụng Cloudinary để tải và lưu trữ hình ảnh trong Spring Boot. Hoàn thành các bài thực hành DynamoDB và tích hợp Cloudinary vào dự án. Công việc đã thực hiện trong tuần Ngày Nhiệm Vụ Ngày Bắt Đầu Ngày Hoàn Thành Tài Liệu Tham Khảo 2 - Sửa lỗi trong chức năng đăng ký/đăng nhập\n- Tìm hiểu về dịch vụ MoMo và cách tích hợp vào Spring Boot 29/09/2025 29/09/2025 AWS Study Group 3 - Họp nhóm để thảo luận tiến độ dự án\n- Phát triển và tích hợp thanh toán MoMo vào dự án 30/09/2025 30/09/2025 4 - Họp nhóm để bàn về đề xuất dự án và phân công nhiệm vụ cho các thành viên\n- Hoàn thiện tích hợp thanh toán MoMo 01/10/2025 01/10/2025 5 - Tìm hiểu về DynamoDB\n- Học cách sử dụng Cloudinary và tích hợp chức năng tải ảnh lên trong Spring Boot 02/10/2025 02/10/2025 AWS Study Group 6 - Thực hành các bài lab về DynamoDB\n- Tích hợp Cloudinary vào dự án 03/10/2025 03/10/2025 AWS Study Group Thành tựu tuần 4 Đã sửa lỗi và cải thiện tính ổn định cho chức năng đăng ký/đăng nhập. Tích hợp thành công cổng thanh toán MoMo vào dự án backend. Tham gia các buổi họp nhóm để đánh giá tiến độ và phân chia nhiệm vụ phát triển. Có thêm kinh nghiệm thực hành với Amazon DynamoDB thông qua các bài lab. Học cách sử dụng Cloudinary để lưu trữ hình ảnh hiệu quả và tích hợp thành công vào dự án. Nâng cao chức năng backend tổng thể với các tính năng thanh toán và tải ảnh, tạo nền tảng vững chắc cho việc mở rộng hệ thống trong tương lai. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week5/",
	"title": "Tuần 5",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu tuần 5 Tìm hiểu và thực hành với Amazon ElastiCache để cải thiện hiệu suất ứng dụng thông qua bộ nhớ đệm. Nghiên cứu và triển khai Google OAuth 2 để tích hợp nhiều tùy chọn đăng nhập cho người dùng. Tìm hiểu và nghiên cứu Amazon CloudFront nhằm tối ưu phân phối nội dung và tăng tốc độ truy cập trang web. Hoàn thành các bài thực hành (lab) về ElastiCache và CloudFront để có thêm kinh nghiệm thực tế. Tìm hiểu về Edge Computing với Amazon CloudFront và Lambda@Edge. Nghiên cứu và tích hợp MoMo IPN (Instant Payment Notification) để xác minh trạng thái thanh toán. Học cách tích hợp Amazon S3 để lưu trữ, tải lên và tải xuống tệp tin trong dự án. Công việc đã thực hiện trong tuần Ngày Nhiệm Vụ Ngày Bắt Đầu Ngày Hoàn Thành Tài Liệu Tham Khảo 2 - Tìm hiểu về Amazon ElastiCache\n- Học về Google OAuth 2 để tích hợp nhiều tùy chọn đăng nhập vào dự án 06/10/2025 06/10/2025 AWS Study Group 3 - Nghiên cứu về Amazon CloudFront\n- Phát triển và tích hợp OAuth 2 vào dự án 07/10/2025 07/10/2025 AWS Study Group 4 - Thực hành các bài lab về Amazon ElastiCache và Amazon CloudFront\n- Hoàn thiện việc tích hợp OAuth 2 08/10/2025 08/10/2025 AWS Study Group 5 - Tìm hiểu về điện toán biên (Edge Computing) với Amazon CloudFront và Lambda@Edge\n- Nghiên cứu về MoMo IPN để xác minh trạng thái thanh toán 09/10/2025 09/10/2025 AWS Study Group 6 - Tích hợp MoMo IPN vào dự án\n- Học cách tích hợp Amazon S3 để lưu trữ, tải lên và tải xuống tệp tin 10/10/2025 10/10/2025 AWS Study Group Thành tựu tuần 5 Hiểu rõ hơn về Amazon ElastiCache và cách sử dụng để tăng hiệu suất ứng dụng thông qua bộ nhớ đệm. Triển khai thành công Google OAuth 2, giúp hệ thống hỗ trợ nhiều hình thức đăng nhập. Hoàn thành các bài thực hành về Amazon CloudFront, nắm được cách cấu hình CDN và phân phối nội dung hiệu quả. Tìm hiểu và áp dụng Edge Computing với Lambda@Edge để xử lý yêu cầu gần người dùng hơn, giảm độ trễ truy cập. Tích hợp thành công MoMo IPN vào dự án, giúp tự động xác minh trạng thái thanh toán. Học và áp dụng Amazon S3 để quản lý tệp tin an toàn, hỗ trợ chức năng tải lên và tải xuống. Cải thiện khả năng mở rộng, bảo mật và hiệu suất tổng thể của hệ thống thông qua việc ứng dụng nhiều dịch vụ AWS thực tế. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week6/",
	"title": "Tuần 6",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu Tuần 6 Tích hợp Amazon S3 vào dự án để hỗ trợ chức năng tải lên và tải xuống hình ảnh. Hoàn thành các bài lab về AWS CloudFront và Lambda@Edge để củng cố kiến thức về phân phối nội dung. Nghiên cứu Windows Workloads trên AWS và Directory Services sử dụng AWS Managed Microsoft AD. Tìm hiểu và đánh giá các API bên thứ ba để tính phí vận chuyển, đặc biệt là Giao Hàng Tiết Kiệm (GHTK). Bắt đầu tích hợp API GHTK vào dự án hiện tại. Củng cố kiến thức về Kiến trúc bảo mật (Secure Architecture) để chuẩn bị cho bài kiểm tra giữa kỳ. Tìm hiểu về việc di chuyển máy ảo (VM Migration) bằng AWS VM Import/Export. Công việc Thực hiện Trong Tuần Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Tích hợp S3 vào dự án với chức năng tải lên và tải xuống hình ảnh - Thực hiện các bài lab liên quan đến Amazon CloudFront và Lambda@Edge 13/10/2025 13/10/2025 AWS Study Group 3 - Học về Windows Workloads trên AWS và Directory Services với AWS Managed Microsoft AD - Cân nhắc và đánh giá các dịch vụ có thể sử dụng để tính phí vận chuyển trong dự án 14/10/2025 14/10/2025 AWS Study Group 4 - Hoàn thành các bài lab liên quan đến Windows Workloads trên AWS và Directory Services với AWS Managed Microsoft AD - Nghiên cứu và tìm hiểu về API Giao Hàng Tiết Kiệm để tính phí vận chuyển 15/10/2025 15/10/2025 AWS Study Group Tài liệu API GHTK 5 - Bắt đầu tích hợp API Giao Hàng Tiết Kiệm vào dự án - Thực hiện các bài lab về Xây dựng Ứng dụng Web Có Tính Sẵn Sàng Cao - Tham gia buổi họp với chủ đề \u0026ldquo;Reinventing DevSecOps\u0026rdquo; 16/10/2025 16/10/2025 AWS Study Group 6 - Ôn tập kiến thức về Kiến trúc Bảo mật để chuẩn bị cho bài thi giữa kỳ - Tiếp tục tích hợp API Giao Hàng Tiết Kiệm - Đọc về chủ đề Di chuyển Máy Ảo với AWS VM Import/Export 17/10/2025 17/10/2025 AWS Study Group Thành tựu Tuần 6 Đã tích hợp thành công Amazon S3 vào dự án, cho phép tải lên và tải xuống hình ảnh. Hoàn thành các bài lab thực hành về AWS CloudFront và Lambda@Edge, nắm được kiến thức về điện toán biên và tối ưu hóa CDN. Nghiên cứu và hoàn thành các bài lab về Windows Workloads và AWS Managed Microsoft AD, hiểu rõ cách quản lý môi trường lai (hybrid). Đã nghiên cứu và thử nghiệm API tính phí vận chuyển của GHTK, bắt đầu tích hợp vào dự án bằng Spring Boot. Tham gia buổi họp nhóm với chủ đề “Reinventing DevSecOps”, thảo luận về việc tích hợp bảo mật vào quy trình CI/CD. Ôn tập các nguyên tắc Kiến trúc Bảo mật bao gồm IAM, mã hóa và WAF để chuẩn bị cho bài thi giữa kỳ. Đọc và tóm tắt các điểm chính về di chuyển máy ảo bằng công cụ AWS VM Import/Export. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week7/",
	"title": "Tuần 7",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu Tuần 7 Củng cố kiến thức về các chủ đề kiến trúc AWS, bao gồm Kiến trúc chịu lỗi (Resilient Architecture) và Kiến trúc hiệu năng cao (High-Performing Architecture) để chuẩn bị cho bài thi giữa kỳ. Hoàn thành bài lab về Di chuyển Máy Ảo (VM Migration) bằng AWS VM Import/Export. Tiếp tục tích hợp và sửa lỗi API Giao Hàng Tiết Kiệm (GHTK) để tính phí vận chuyển. Tìm hiểu và áp dụng các khái niệm về Di chuyển Cơ sở dữ liệu (Database Migration) bằng AWS DMS và SCT. Nghiên cứu về Tối ưu hóa chi phí (Cost Optimization) và Vận hành xuất sắc (Operational Excellence) trong AWS. Tìm hiểu AWS Cognito để chuẩn bị cho việc tích hợp xác thực người dùng trong dự án. Hoàn thiện sơ đồ kiến trúc ứng dụng sử dụng các dịch vụ AWS. Công việc Thực hiện Trong Tuần Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Ôn tập kiến thức về Kiến trúc chịu lỗi và các dịch vụ như EC2, S3,… để chuẩn bị cho bài thi giữa kỳ - Hoàn thành bài lab về Di chuyển Máy Ảo bằng AWS VM Import/Export - Tiếp tục tích hợp và sửa lỗi API GHTK 20/10/2025 20/10/2025 AWS Study Group Tài liệu API GHTK 3 - Sửa các lỗi nhỏ trong giỏ hàng sau khi thanh toán - Ôn tập kiến thức về Kiến trúc Hiệu năng cao và các dịch vụ như RDS, DynamoDB,… 21/10/2025 21/10/2025 AWS Study Group 4 - Hoàn thành tích hợp API GHTK để tính phí vận chuyển - Đọc tài liệu về Di chuyển Cơ sở dữ liệu bằng AWS DMS và SCT - Tham gia họp nhóm để thảo luận và chỉnh sửa sơ đồ ứng dụng sử dụng AWS 22/10/2025 22/10/2025 AWS Study Group Tài liệu API GHTK 5 - Ôn tập kiến thức về Tối ưu hóa chi phí và các dịch vụ liên quan của AWS - Nghiên cứu về AWS Cognito 23/10/2025 23/10/2025 AWS Study Group 6 - Học về Nguyên tắc Vận hành Xuất sắc (Operational Excellence) trong AWS - Tiếp tục nghiên cứu về AWS Cognito để tích hợp vào dự án - Hoàn thiện sơ đồ kiến trúc ứng dụng với các dịch vụ AWS 24/10/2025 24/10/2025 AWS Study Group Thành tựu Tuần 7 Đã ôn tập và củng cố kiến thức về EC2, S3, RDS, và DynamoDB, nắm vững các nguyên tắc về kiến trúc chịu lỗi và hiệu năng cao. Hoàn thành thực hành Di chuyển Máy Ảo (VM Migration) bằng AWS VM Import/Export. Tích hợp và kiểm thử thành công API GHTK để tính phí vận chuyển trong dự án. Sửa các lỗi còn tồn tại trong chức năng giỏ hàng sau khi thanh toán. Phối hợp cùng nhóm hoàn thiện sơ đồ kiến trúc ứng dụng với các dịch vụ AWS. Hiểu rõ hơn về Tối ưu hóa chi phí và Vận hành xuất sắc trong AWS. Tìm hiểu về AWS Cognito và bắt đầu lập kế hoạch tích hợp chức năng xác thực người dùng vào dự án. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week8/",
	"title": "Tuần 8",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu Tuần 8 Học và tích hợp AWS Cognito vào dự án để triển khai chức năng xác thực người dùng an toàn. Ôn tập và củng cố kiến thức về các dịch vụ cốt lõi của AWS (EC2, S3, IAM, MFA, SCP, Encryption, Security Groups, NACLs, GuardDuty, Shield, WAF, Secrets Manager). Nghiên cứu các khái niệm về Kiến trúc chịu lỗi (Resilient Architecture) bao gồm Multi-AZ, Multi-Region, DR Strategies, Auto Scaling, Route 53, Load Balancing, Backup \u0026amp; Restore để chuẩn bị cho bài thi giữa kỳ AWS. Thực hành các bài thi mẫu (practice exams) để đánh giá và nâng cao kiến thức về các dịch vụ AWS. Công việc Thực hiện Trong Tuần Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Học AWS Cognito để tích hợp vào dự án - Làm lại các bài lab về EC2 và S3 để củng cố kiến thức cho bài thi giữa kỳ 27/10/2025 27/10/2025 AWS Study Group 3 - Bắt đầu tích hợp AWS Cognito vào dự án - Đọc tài liệu về IAM, MFA, SCP và Encryption để chuẩn bị cho bài thi giữa kỳ 28/10/2025 28/10/2025 AWS Study Group KungFuTech AWS Course 4 - Tìm hiểu và nghiên cứu về Security Groups, NACLs, GuardDuty, Shield, WAF, Secrets Manager để nắm vững Kiến trúc bảo mật (Secure Architectures) - Làm bài thi mẫu về các dịch vụ AWS 29/10/2025 29/10/2025 AWS Study Group KungFuTech AWS Course Practice Exam 5 - Đọc tài liệu về Multi-AZ, Multi-Region, DR Strategies, Auto Scaling, Route 53, Load Balancing, Backup \u0026amp; Restore để hiểu rõ Kiến trúc chịu lỗi (Resilient Architecture) - Làm bài thi mẫu để củng cố kiến thức về các dịch vụ AWS 30/10/2025 30/10/2025 AWS Study Group KungFuTech AWS Course Practice Exam 6 - Tham gia bài thi giữa kỳ AWS 31/10/2025 31/10/2025 Thành tựu Tuần 8 Đã học và bắt đầu tích hợp AWS Cognito vào dự án để quản lý xác thực người dùng. Hoàn thành nhiều bài lab về EC2 và S3, củng cố kỹ năng thực hành và kiến thức chuẩn bị cho bài thi giữa kỳ. Đọc và nghiên cứu sâu về kiến trúc bảo mật và kiến trúc chịu lỗi của AWS, nâng cao hiểu biết về cách thiết kế hệ thống an toàn và linh hoạt. Hoàn thành nhiều bài thi mẫu AWS, xác định điểm yếu và củng cố sự tự tin trước kỳ thi. Tham gia bài thi giữa kỳ AWS, áp dụng kiến thức đã học vào bài kiểm tra thực tế. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week9/",
	"title": "Tuần 9",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu Tuần 9 Tiếp tục tích hợp AWS Cognito vào dự án để xác thực người dùng và lưu trữ dữ liệu. Học và thực hành các chiến lược Khôi phục sau thảm họa (Disaster Recovery - DR) bằng AWS Elastic Disaster Recovery. Nghiên cứu các phương pháp tối ưu hóa hiệu suất hệ thống bằng các dịch vụ AWS. Tìm hiểu và triển khai Tự động hóa Serverless bằng AWS Lambda. Sửa các lỗi liên quan đến Redis trong dự án để đảm bảo tính ổn định và hiệu năng. Công việc Thực hiện Trong Tuần Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Tiếp tục tích hợp AWS Cognito vào dự án - Đọc tài liệu để tìm hiểu về Khôi phục sau thảm họa và cách thực hiện với AWS Elastic Disaster Recovery 03/11/2025 03/11/2025 AWS Study Group 3 - Thực hành bài lab về Khôi phục sau thảm họa với AWS Elastic Disaster Recovery - Sửa lỗi liên quan đến Redis trong dự án 04/11/2025 04/11/2025 AWS Study Group 4 - Tích hợp thành công AWS Cognito để đăng ký/đăng nhập tài khoản và lưu dữ liệu vào AWS User Pools - Cải thiện bằng cách lưu thông tin cơ bản của người dùng vào cơ sở dữ liệu nội bộ 05/11/2025 05/11/2025 AWS Study Group 5 - Đọc tài liệu về cách tối ưu hệ thống bằng AWS - Nghiên cứu cách lưu thông tin người dùng khi đăng ký/đăng nhập bằng AWS Cognito vào cơ sở dữ liệu nội bộ 06/11/2025 06/11/2025 AWS Study Group 6 - Đọc tài liệu về Tự động hóa Serverless bằng AWS Lambda - Hoàn thành bài lab về AWS Lambda - Tiếp tục tìm hiểu các dịch vụ AWS được sử dụng trong dự án cuối kỳ để chuẩn bị tích hợp 07/11/2025 07/11/2025 AWS Study Group Thành tựu Tuần 9 Hoàn thành tích hợp AWS Cognito, cho phép người dùng đăng ký/đăng nhập và lưu thông tin vào AWS User Pools và cơ sở dữ liệu nội bộ. Thực hành thành công AWS Elastic Disaster Recovery, hiểu rõ cách bảo vệ và khôi phục hệ thống hiệu quả. Sửa các lỗi Redis, giúp hệ thống ổn định và hoạt động tốt hơn. Nghiên cứu và áp dụng các kỹ thuật tối ưu hóa hệ thống theo tiêu chuẩn AWS. Hoàn thành bài lab về AWS Lambda, nâng cao kiến thức về tự động hóa và mô hình không máy chủ (serverless). Củng cố kiến thức tổng thể về các dịch vụ AWS phục vụ cho dự án cuối kỳ và chuẩn bị cho các bước tích hợp tiếp theo. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": " Tuần 1: Làm quen với AWS và các dịch vụ cơ bản của AWS Tuần 2: Tìm hiểu các dịch vụ AWS cơ bản (S3, RDS, CloudWatch, Lightsail, EC2 Auto Scaling) và thực hành xây dựng backend với Spring Boot và PostgreSQL. Tuần 3: Thiết lập dự án backend, phát triển chức năng xác thực (đăng ký, đăng nhập, JWT) và thực hành với Route 53, EC2 Auto Scaling, cùng AWS CLI. Tuần 4: Nâng cấp hệ thống xác thực và tích hợp thanh toán MoMo cùng Cloudinary, đồng thời thực hành các dịch vụ AWS cơ bản. Tuần 5: Tìm hiểu các dịch vụ AWS nâng cao và tích hợp OAuth 2, MoMo IPN, cùng Amazon S3 vào dự án. Tuần 6: Tập trung vào việc tích hợp Amazon S3 và API GHTK, hoàn thành các bài lab AWS, nghiên cứu kiến trúc bảo mật và chuẩn bị cho bài kiểm tra giữa kỳ. Tuần 7: Củng cố kiến thức về kiến trúc và dịch vụ AWS, đồng thời tìm hiểu AWS Cognito để nâng cao dự án. Tuần 8: Củng cố kiến thức AWS về kiến trúc bảo mật và chịu lỗi, thực hành lab EC2 và S3, tích hợp AWS Cognito, và hoàn thành bài thi giữa kỳ AWS. Tuần 9: Phát triển dự án AWS với việc hoàn thiện tích hợp Cognito, thực hành Khôi phục sau thảm họa bằng AWS Elastic Disaster Recovery, tối ưu hệ thống và tự động hóa bằng AWS Lambda. Tuần 10: Củng cố tích hợp Cognito, lấy thuộc tính người dùng, xử lý lỗi token và tăng cường giám sát hệ thống qua các bài lab CloudWatch và Grafana. Tuần 11: Hoàn thiện quản lý người dùng bằng cách đồng bộ cập nhật giữa Cognito và cơ sở dữ liệu, hoàn thành các lab quản lý tài nguyên AWS và chuẩn bị triển khai đăng xuất an toàn. Tuần 12: Cải thiện quản lý người dùng Cognito, thêm quyền admin, triển khai đăng xuất an toàn và chuẩn bị cho việc triển khai lên AWS. "
},
{
	"uri": "//localhost:1313/vi/2-proposal/",
	"title": "Đề xuất",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/4-events/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Báo cáo tổng hợp: “DevOps trên AWS” Mục tiêu Sự kiện Hiểu các nguyên tắc cốt lõi của văn hóa DevOps và các chỉ số hiệu suất chính (DORA, MTTR). Nắm vững chuỗi công cụ CI/CD của AWS để tự động hóa việc xây dựng (build), kiểm thử (test) và triển khai (deployment). Tìm hiểu các khái niệm Cơ sở hạ tầng dưới dạng Mã (IaC) sử dụng CloudFormation và AWS CDK. Khám phá các chiến lược container hóa sử dụng ECR, ECS, EKS và App Runner. Triển khai khả năng quan sát toàn diện (full-stack observability) và giám sát với CloudWatch và X-Ray. Diễn giả Các Chuyên gia DevOps của AWS Các Kiến trúc sư Giải pháp Cấp cao Điểm nhấn Chính Văn hóa \u0026amp; Tư duy DevOps Tóm tắt: Tích hợp với các khái niệm AI/ML từ các phiên trước. Các chỉ số quan trọng: Tập trung vào Tần suất triển khai, Thời gian thực hiện thay đổi, Thời gian trung bình để khôi phục (MTTR) và Tỷ lệ lỗi khi thay đổi (các chỉ số DORA). Chuyển đổi văn hóa: Chuyển từ các nhóm làm việc riêng lẻ (siloed) sang mô hình chia sẻ trách nhiệm. Đường ống CI/CD trên AWS Kiểm soát nguồn (Source Control): Sử dụng AWS CodeCommit và triển khai các chiến lược Git như GitFlow và Trunk-based. Xây dựng \u0026amp; Kiểm thử: Cấu hình AWS CodeBuild để kiểm thử và biên dịch tự động. Triển khai: Sử dụng AWS CodeDeploy để thực hiện các chiến lược triển khai an toàn: Blue/Green: Giảm thiểu thời gian ngừng hoạt động và rủi ro. Canary: Triển khai dần dần cho một nhóm nhỏ người dùng. Rolling: Cập nhật các instance theo từng bước. Điều phối: Kết nối tất cả các khâu với AWS CodePipeline Cơ sở hạ tầng dưới dạng Mã (IaC) AWS CloudFormation: Định nghĩa hạ tầng bằng template, stack và quản lý sự sai lệch cấu hình (drift). AWS CDK (Cloud Development Kit): Sử dụng ngôn ngữ lập trình quen thuộc để định nghĩa tài nguyên đám mây dưới dạng các cấu trúc mã (constructs). So sánh: Lựa chọn giữa template khai báo (CloudFormation) và mã mệnh lệnh (CDK) dựa trên kỹ năng của đội ngũ. Dịch vụ Container \u0026amp; Khả năng quan sát Quản lý Container: Lưu trữ image trong Amazon ECR với các chính sách vòng đời. Điều phối: Lựa chọn giữa Amazon ECS (đơn giản, native AWS) và Amazon EKS (chuẩn Kubernetes), hoặc AWS App Runner để triển khai đơn giản kiểu PaaS. Giám sát: Sử dụng Amazon CloudWatch cho các chỉ số/cảnh báo và AWS X-Ray cho truy vết phân tán để xác định điểm nghẽn hiệu năng. Bài học Chính (Key Takeaways) Chiến lược DevOps Tự động hóa là ưu tiên: Triển khai thủ công dễ gặp lỗi; mọi thứ từ hạ tầng đến triển khai mã nguồn cần được tự động hóa. Đo lường: Bạn không thể cải thiện những gì bạn không đo lường. Sử dụng chỉ số DORA để theo dõi tốc độ và sự ổn định. Dịch chuyển sang trái (Shift Left): Tích hợp kiểm thử và bảo mật sớm trong pipeline CI/CD, thay vì để ở cuối quy trình. Kiến trúc Kỹ thuật Hạ tầng bất biến (Immutable Infrastructure): Coi máy chủ là tài nguyên dùng một lần; thay thế chúng thay vì vá lỗi tại chỗ. Container hóa: Tách biệt ứng dụng khỏi hệ điều hành bên dưới để đảm bảo tính nhất quán giữa các môi trường (Dev, Test, Prod). Khả năng quan sát: Vượt ra ngoài việc giám sát \u0026ldquo;bật/tắt\u0026rdquo; đơn giản để có thông tin sâu sắc bằng cách sử dụng truy vết phân tán. Ứng dụng vào Công việc Triển khai CI/CD: Thiết lập CodePipeline cho các dự án hiện tại để tự động hóa quy trình build/deploy cho ứng dụng Spring Boot/React. Áp dụng IaC: Bắt đầu định nghĩa tài nguyên AWS (database, S3 bucket, Cognito User Pools) bằng AWS CDK thay vì dùng console. Container hóa: Dockerize các microservices hiện có và đẩy image lên ECR. Nâng cao giám sát: Thêm X-Ray vào các dịch vụ backend để trực quan hóa độ trễ API và hiệu năng truy vấn cơ sở dữ liệu. Trải nghiệm Sự kiện Tham dự hội thảo “DevOps on AWS” đã cung cấp một lộ trình thực tế để tự động hóa vòng đời phân phối phần mềm. Nó thu hẹp khoảng cách giữa việc viết code và chạy nó một cách đáng tin cậy trên môi trường production (thực tế). Các trải nghiệm chính bao gồm:\nHọc hỏi từ chuyên gia Làm rõ \u0026ldquo;Ma trận thuật ngữ\u0026rdquo; của các công cụ AWS (CodeCommit, CodeBuild, CodeDeploy, CodePipeline) và cách chúng tích hợp. Hiểu giá trị chiến lược của chỉ số DORA trong việc chứng minh hiệu quả đầu tư DevOps với các bên liên quan. Tiếp cận kỹ thuật thực tế CI/CD Walkthrough: Bản demo pipeline đầy đủ cho thấy chính xác cách thay đổi code kích hoạt build và deploy tự động. IaC Implementation: Xem AWS CDK hoạt động là một điểm nhấn—viết hạ tầng bằng Java/TypeScript trực quan hơn nhiều cho lập trình viên so với viết template JSON/YAML. Deployment Strategies: Trực quan hóa Blue/Green deployments đã chứng minh cách phát hành bản cập nhật mà không có thời gian chết (zero downtime). Kết nối và thảo luận Thảo luận về sự đánh đổi giữa ECS và EKS với đồng nghiệp, nhận ra rằng đối với nhiều dự án, ECS hoặc App Runner cung cấp con đường nhanh hơn để ra production với ít chi phí vận hành hơn. Trao đổi ý tưởng về cách xử lý database migrations (di chuyển dữ liệu) trong một pipeline CI/CD. Bài học rút ra Phát hiện sai lệch (Drift Detection) trong CloudFormation là rất quan trọng để duy trì tính toàn vẹn của hạ tầng. Khả năng quan sát (Observability) không phải là tùy chọn đối với microservices; nếu không có X-Ray, việc gỡ lỗi kiến trúc phân tán gần như là không thể. Một nền tảng DevOps vững chắc giúp giảm đáng kể thời gian trung bình để khôi phục (MTTR), cho phép các team đổi mới nhanh hơn mà ít sợ làm hỏng hệ thống production. Ảnh sự kiện "
},
{
	"uri": "//localhost:1313/vi/2-proposal/2.2-createiamrole/",
	"title": "Tạo IAM Role",
	"tags": [],
	"description": "",
	"content": "Tạo IAM Role Trong bước này chúng ta sẽ tiến hành tạo IAM Role. Trong IAM Role này sẽ được gán policy AmazonSSMManagedInstanceCore, đây là policy cho phép máy chủ EC2 có thể giao tiếp với Session Manager.\nTruy cập vào giao diện quản trị dịch vụ IAM Ở thanh điều hướng bên trái, click Roles. Click Create role. Click AWS service và click EC2. Click Next: Permissions. Trong ô Search, điền AmazonSSMManagedInstanceCore và ấn phím Enter để tìm kiếm policy này. Click chọn policy AmazonSSMManagedInstanceCore. Click Next: Tags. Click Next: Review. Đặt tên cho Role là SSM-Role ở Role Name Click Create Role . Tiếp theo chúng ta sẽ thực hiện kết nối đến các máy chủ EC2 chúng ta đã tạo bằng Session Manager.\n"
},
{
	"uri": "//localhost:1313/vi/2-proposal/2.1-createec2/2.1.2-createpublicsubnet/",
	"title": "Tạo Public subnet",
	"tags": [],
	"description": "",
	"content": "Tạo Public subnet Click Subnets. Click Create subnet. Tại trang Create subnet. Tại mục VPC ID click chọn Lab VPC. Tại mục Subnet name điền Lab Public Subnet. Tại mục Availability Zone chọn Availability zone đầu tiên. Tại mục IPv4 CIRD block điền 10.10.1.0/24. Kéo xuống cuối trang , click Create subnet.\nClick chọn Lab Public Subnet.\nClick Actions. Click Edit subnet settings. Click chọn Enable auto-assign public IPv4 address. Click Save. Click Internet Gateways. Click Create internet gateway. Tại trang Create internet gateway. Tại mục Name tag điền Lab IGW. Click Create internet gateway. Sau khi tạo thành công, click Actions. Click Attach to VPC. Tại trang Attach to VPC. Tại mục Available VPCs chọn Lab VPC. Click Attach internet gateway. Kiểm tra quá trình attach thành công như hình dưới. Tiếp theo chúng ta sẽ tạo một custom route table để gán vào Lab Public Subnet. Click Route Tables. Click Create route table. Tại trang Create route table. Tại mục Name, điền Lab Publicrtb. Tại mục VPC, chọn Lab VPC. Click Create route table. Sau khi tạo route table thành công. Click Edit routes. Tại trang Edit routes. Click Add route. Tại mục Destination điền 0.0.0.0/0 Tại mục Target chọn Internet Gateway sau đó chọn Lab IGW. Click Save changes. Click tab Subnet associations. Click Edit subnet associations để tiến hành associate custom routable chúng ta vừa tạo vào Lab Public Subnet. Tại trang Edit subnet associations. Click chọn Lab Public Subnet. Click Save associations. Kiểm tra thông tin route table đã được associate với Lab Public Subnet và thông tin route đi internet đã được trỏ đến Internet Gateway như hình dưới. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week10/",
	"title": "Tuần 10",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu Tuần 10 Tìm hiểu AWS Cognito Identity Provider và chuẩn bị tích hợp đăng nhập bằng Google. Nghiên cứu cách lấy thuộc tính người dùng từ Cognito và lưu vào cơ sở dữ liệu nội bộ sau khi đăng ký. Khám phá các phương pháp lấy thông tin người dùng sau khi xác thực bằng Cognito. Xử lý các lỗi liên quan đến token của AWS Cognito. Đồng bộ thời gian hết hạn token của Cognito với token do backend tạo ra. Hoàn thành các bài lab về giám sát nâng cao với CloudWatch và Grafana. Công việc Thực hiện Trong Tuần Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Tìm hiểu về Identity Provider trong AWS Cognito và lập kế hoạch tích hợp đăng nhập bằng Google 10/11/2025 10/11/2025 AWS Study Group 3 - Tìm hiểu cách lấy thông tin người dùng và lưu vào DB nội bộ - Hoàn thành bài lab Advanced Monitoring với CloudWatch \u0026amp; Grafana 11/11/2025 11/11/2025 AWS Study Group 4 - Triển khai các phương thức lấy thông tin người dùng sau khi xác thực bằng Cognito 12/11/2025 12/11/2025 5 - Lấy thành công thông tin cơ bản (tên, email) từ Cognito và lưu vào cơ sở dữ liệu nội bộ - Sửa các lỗi liên quan đến token của AWS Cognito 13/11/2025 13/11/2025 6 - Đồng bộ thời gian hết hạn token Cognito với token backend - Hoàn thành bài lab CloudWatch Advanced Workshop 14/11/2025 14/11/2025 AWS Study Group Thành tựu Tuần 10 Tìm hiểu và nắm được cách hoạt động của Cognito Identity Providers, chuẩn bị cho tính năng đăng nhập bằng Google. Lấy được thông tin người dùng từ Cognito (tên, email) và lưu vào cơ sở dữ liệu nội bộ. Triển khai nhiều phương pháp để truy xuất dữ liệu người dùng sau xác thực. Sửa các lỗi liên quan đến token trong quy trình xác thực Cognito. Đồng bộ thời gian hết hạn token giữa Cognito và hệ thống backend. Hoàn thành các bài lab nâng cao với CloudWatch và Grafana, tăng cường kỹ năng giám sát và quan sát hệ thống. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week11/",
	"title": "Tuần 11",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu Tuần 11 Tham dự sự kiện AWS Cloud Mastery #2 tại văn phòng AWS. Viết bài cảm nhận về Hội thảo AWS Cloud Mastery #1. Thực hiện các bài lab về Tổ chức tài nguyên bằng Tags \u0026amp; Resource Groups. Thực hành lab về Kiểm soát truy cập bằng IAM và Resource Tags. Hoàn thành lab AWS Systems Manager về tự động hóa và quản lý cấu hình. Phát triển API cập nhật thông tin người dùng lên cả cơ sở dữ liệu nội bộ và AWS Cognito. Phối hợp với đội front-end để đồng bộ chức năng. Nghiên cứu cách triển khai chức năng đăng xuất (logout) an toàn cho người dùng Cognito. Công việc Thực hiện Trong Tuần Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Tham dự sự kiện AWS Cloud Mastery #2 - Viết bài cảm nhận về AWS Cloud Mastery #1 17/11/2025 17/11/2025 3 - Hoàn thành lab Resource Organization with Tags \u0026amp; Resource Groups - Hoàn thành lab IAM Tag-based Access Control 18/11/2025 18/11/2025 AWS Study Group 4 - Hoàn thành lab AWS Systems Manager - Phát triển chức năng cập nhật thông tin người dùng trên DB nội bộ và AWS Cognito 19/11/2025 19/11/2025 AWS Study Group 5 - Tiếp tục phát triển API cập nhật thông tin người dùng - Họp với nhóm front-end để thảo luận tiến độ và phối hợp 20/11/2025 20/11/2025 6 - Tiếp tục hoàn thiện API cập nhật thông tin người dùng - Nghiên cứu các phương án đăng xuất an toàn trên Cognito 21/11/2025 21/11/2025 Thành tựu Tuần 11 Tham dự thành công sự kiện AWS Cloud Mastery #2 và học hỏi thêm nhiều kinh nghiệm về kiến trúc và thực hành AWS. Hoàn thành bài viết cảm nhận về sự kiện Cloud Mastery #1. Hoàn thành các lab về Resource Tags, Resource Groups và IAM Tag-based Permissions, củng cố kiến thức về quản lý và phân quyền tài nguyên. Hoàn thành lab AWS Systems Manager, nâng cao hiểu biết về tự động hóa và vận hành hệ thống. Tiến bộ đáng kể trong việc xây dựng API cập nhật thông tin người dùng đồng thời trên Cognito và cơ sở dữ liệu nội bộ. Phối hợp tốt với nhóm front-end để đảm bảo luồng cập nhật thông tin người dùng thống nhất. Nghiên cứu các phương án logout Cognito, chuẩn bị triển khai tính năng đăng xuất an toàn cho hệ thống. "
},
{
	"uri": "//localhost:1313/vi/1-introduce/week12/",
	"title": "Tuần 12",
	"tags": [],
	"description": "",
	"content": "NHẬT KÝ CÔNG VIỆC Mục tiêu Tuần 12 Viết bài cảm nhận về sự kiện AWS Cloud Mastery #2. Cấu hình lại đăng nhập Cognito với trường sub mới được ánh xạ vào cơ sở dữ liệu. Triển khai chức năng đăng xuất an toàn với AWS Cognito. Sửa lỗi logic xác thực liên quan đến tên người dùng khi tạo tài khoản. Thêm chức năng cho Admin bật/tắt tài khoản người dùng ở cả cơ sở dữ liệu nội bộ và AWS Cognito. Nghiên cứu quy trình deploy dự án lên AWS. Cấu hình lại routing sau khi đăng nhập bằng Cognito. Refactor logic đăng xuất và routing. Công Việc Thực Hiện Trong Tuần Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Viết bài cảm nhận AWS Cloud Mastery #2 - Cấu hình lại đăng nhập Cognito với trường sub mới trong database 24/11/2025 24/11/2025 https://luma.com/39t066sy 3 - Triển khai chức năng đăng xuất Cognito - Sửa logic xác thực liên quan đến tên người dùng khi tạo tài khoản 25/11/2025 25/11/2025 4 - Tiếp tục triển khai logout handler của Cognito - Thêm chức năng Admin bật/tắt tài khoản người dùng ở local DB và AWS Cognito 26/11/2025 26/11/2025 5 - Nghiên cứu cách deploy dự án lên AWS - Cấu hình lại routing sau khi đăng nhập bằng Cognito 27/11/2025 27/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Refactor chức năng đăng xuất với AWS Cognito - Sửa routing cho chức năng đăng nhập 28/11/2025 28/11/2025 Thành Tựu Tuần 12 Hoàn thành bài cảm nhận về AWS Cloud Mastery #2. Cập nhật luồng đăng nhập để xử lý đúng trường sub mới từ Cognito. Triển khai và tối ưu chức năng đăng xuất an toàn với Cognito. Sửa lỗi logic xác thực khi tạo mới tên người dùng. Thêm chức năng Admin bật/tắt tài khoản người dùng trên cả Cognito và cơ sở dữ liệu nội bộ. Nghiên cứu quy trình deploy dự án lên AWS để chuẩn bị cho môi trường production. Cải thiện routing cho luồng đăng nhập và đăng xuất nhằm tối ưu trải nghiệm người dùng. "
},
{
	"uri": "//localhost:1313/vi/3-translatedblog/",
	"title": "Blog đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Tăng tốc lập kế hoạch chiến dịch Marketing gấp 3 lần với Treasure Data AI Agents được hỗ trợ bởi Amazon Bedrock Bài viết giải thích cách Treasure Data, hợp tác cùng Amazon Bedrock (AWS), sử dụng AI Agents để tăng tốc quá trình lập kế hoạch chiến dịch marketing lên gấp 3 lần. Các agent như Audience Agent, Research Agent, và Migration Agent giúp phân tích dữ liệu khách hàng, phân khúc đối tượng và tự động hóa việc tạo insight mà không cần chuyên môn kỹ thuật. Với AI Agent Foundry, doanh nghiệp có thể tạo các agent tùy chỉnh đáp ứng nhu cầu riêng, đồng thời đảm bảo bảo mật và tuân thủ. Nghiên cứu tình huống với Nobitel cho thấy thời gian lập kế hoạch giảm ba lần và hiệu suất tăng 20%. Giải pháp này giúp đội ngũ marketing tập trung vào chiến lược, trong khi AI xử lý phân tích, mang lại quá trình tiếp thị nhanh hơn, dựa trên dữ liệu và cá nhân hóa hơn.\nBlog 2 - Xây dựng các tác nhân AI sinh sinh (Generative AI Agents) có khả năng chống chịu cao Bài viết của Yiwen Zhang, Hechmi Khelifi và Jennifer Moran trình bày cách xây dựng các tác nhân AI sinh sinh có khả năng chống chịu khi vận hành trong môi trường sản xuất. Nó giới thiệu khung bảy phần bao gồm mô hình, hạ tầng, công cụ và bảo mật, đồng thời xác định năm dạng lỗi chính như độ trễ cao và phản hồi sai lệch. Tác giả đề xuất các giải pháp như cách ly lỗi, dự phòng và kiểm duyệt thủ công (human-in-the-loop), kết hợp DevOps với các biện pháp an toàn dành riêng cho AI như Amazon Bedrock Guardrails. Nhìn chung, bài viết cung cấp hướng dẫn để đảm bảo triển khai AI đáng tin cậy và có thể mở rộng.\nBlog 3 - Triển khai liền mạch các tác vụ EDA lên AWS bằng giải pháp Synopsys Cloud Hybrid Bài viết nhấn mạnh cách Synopsys Cloud Hybrid, được hỗ trợ bởi AWS, giúp các nhóm thiết kế bán dẫn dễ dàng chạy khối lượng công việc EDA trên đám mây mà không cần chuyển dữ liệu thủ công. Hệ thống tự động đồng bộ dữ liệu giữa môi trường on-premises và cloud theo thời gian thực bằng Amazon EC2 và FSx for NetApp ONTAP, mang lại hiệu suất tương đương hoặc tốt hơn so với tại chỗ. Hỗ trợ các công cụ như VCS và PrimeTime, giải pháp này cũng rút ngắn thời gian thiết lập vài tuần, cung cấp một phương án linh hoạt, nhanh chóng và tiết kiệm chi phí cho thiết kế chip trên AWS.\n"
},
{
	"uri": "//localhost:1313/vi/4-events/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Báo cáo tổng hợp: “Trụ cột Bảo mật AWS Well-Architected” Mục tiêu Sự kiện Nắm vững 5 lĩnh vực của Trụ cột Bảo mật (Security Pillar) trong Khung AWS Well-Architected. Hiểu các nguyên tắc bảo mật cốt lõi: Zero Trust (Không tin cậy bất kỳ ai), Least Privilege (Đặc quyền tối thiểu), và Defense in Depth (Phòng thủ chiều sâu). Học cách thiết kế quản lý danh tính (IAM) an toàn và bảo vệ cơ sở hạ tầng. Triển khai các chiến lược phát hiện liên tục và phản ứng sự cố tự động. Khám phá các kỹ thuật bảo vệ dữ liệu sử dụng KMS và các thực hành tốt nhất về mã hóa. Diễn giả Các Kiến trúc sư Giải pháp Bảo mật AWS Các Chuyên gia Bảo mật Đám mây Điểm nhấn Chính Nền tảng Bảo mật \u0026amp; Danh tính (IAM) Nguyên tắc Cốt lõi: Áp dụng tư duy \u0026ldquo;Zero Trust\u0026rdquo; và \u0026ldquo;Phòng thủ chiều sâu\u0026rdquo; (tạo nhiều lớp kiểm soát bảo mật). Bối cảnh Mối đe dọa: Phân tích các mối đe dọa bảo mật đám mây hàng đầu đặc thù tại thị trường Việt Nam. IAM Hiện đại: Chuyển từ việc sử dụng thông tin xác thực dài hạn (access keys) sang thông tin xác thực tạm thời sử dụng IAM Roles. Kiểm soát Truy cập: Triển khai IAM Identity Center cho SSO và sử dụng Service Control Policies (SCPs) để thiết lập ranh giới quyền hạn trong môi trường đa tài khoản (multi-account). Xác thực: Sử dụng IAM Access Analyzer để xác minh các chính sách và quyền hạn. Phát hiện \u0026amp; Bảo vệ Hạ tầng Giám sát Liên tục: Tập trung hóa khả năng quan sát với CloudTrail (cấp độ tổ chức), GuardDuty (phát hiện mối đe dọa), và Security Hub. Chiến lược Ghi nhật ký (Logging): Bật log tại mọi tầng—VPC Flow Logs cho lưu lượng mạng và ALB/S3 logs cho các mẫu truy cập. An ninh Mạng: Triển khai phân đoạn VPC (subnet public vs. private) và kết hợp Security Groups (stateful - có trạng thái) với NACLs (stateless - không trạng thái). Bảo vệ Biên: Sử dụng AWS WAF và AWS Shield để bảo vệ chống lại DDoS và các khai thác web. Bảo vệ Dữ liệu \u0026amp; Phản ứng Sự cố Mã hóa: Quản lý khóa với AWS KMS (xoay vòng khóa, chính sách) và đảm bảo mã hóa dữ liệu khi lưu trữ (EBS, RDS, S3) và khi truyền tải. Quản lý Bí mật: Thay thế thông tin xác thực được gắn cứng (hardcoded) bằng AWS Secrets Manager và Parameter Store. Kịch bản Phản ứng Sự cố (IR Playbooks): Định nghĩa các quy trình chuẩn cho các tình huống như lộ IAM key, vô tình public S3, và sự cố malware trên EC2. Tự động hóa: Sử dụng Lambda và Step Functions để tự động khắc phục mối đe dọa (ví dụ: cách ly một instance bị xâm nhập). Bài học Chính (Key Takeaways) Tư duy Bảo mật Dịch chuyển sang trái (Shift Left): Bảo mật phải được tích hợp sớm trong giai đoạn thiết kế, không phải thêm vào sau khi đã hoàn thành. Danh tính là Vành đai mới: Trong thế giới cloud-native, quản lý danh tính mạnh mẽ (IAM) quan trọng hơn tường lửa mạng truyền thống. Giả định vi phạm (Assume Breach): Thiết kế hệ thống với giả định rằng kẻ tấn công đã ở bên trong; tập trung vào việc giới hạn phạm vi ảnh hưởng (blast radius). Kiến trúc Kỹ thuật Đặc quyền tối thiểu (Least Privilege): Chỉ cấp cho người dùng và dịch vụ những quyền cần thiết để thực hiện tác vụ của họ, không hơn. Phát hiện dưới dạng Mã (Detection-as-Code): Định nghĩa các quy tắc bảo mật và cảnh báo bằng mã để đảm bảo tính nhất quán và kiểm soát phiên bản. Xoay vòng Tự động: Tự động hóa việc xoay vòng thông tin xác thực cơ sở dữ liệu và API keys để giảm thiểu tác động khi lộ thông tin. Ứng dụng vào Công việc Kiểm toán IAM: Rà soát IAM roles của dự án hiện tại để loại bỏ các quyền không sử dụng và bắt buộc dùng MFA cho tất cả người dùng. Bảo mật Bí mật: Di chuyển thông tin xác thực cơ sở dữ liệu từ file application.properties sang AWS Secrets Manager trong các ứng dụng Spring Boot. Bật GuardDuty: Bật GuardDuty trên tất cả các tài khoản để bắt đầu phát hiện hành vi bất thường ngay lập tức. Soạn thảo Kế hoạch IR: Tạo kịch bản Phản ứng Sự cố cơ bản cho các tình huống dễ xảy ra nhất (ví dụ: khai thác ứng dụng). Trải nghiệm Sự kiện Phiên làm việc “Trụ cột Bảo mật AWS Well-Architected” đã cung cấp cái nhìn sâu sắc về việc bảo mật workload trên đám mây, cân bằng giữa các khung lý thuyết và triển khai thực tế trong bối cảnh Việt Nam.\nHọc hỏi từ chuyên gia Hiểu sâu hơn về Mô hình Trách nhiệm Chia sẻ, làm rõ chính xác khía cạnh bảo mật nào AWS xử lý so với những gì khách hàng phải tự bảo vệ. Học được về những sai lầm phổ biến tại Việt Nam, chẳng hạn như vô tình để lộ dữ liệu công khai, và cách phòng tránh. Tiếp cận kỹ thuật thực tế Mô phỏng Chính sách IAM: Bản demo nhỏ về xác thực chính sách đã chỉ ra cách mô phỏng yêu cầu truy cập để đảm bảo quyền hạn được cấu hình chính xác trước khi triển khai. Vòng đời IR: Đi qua kịch bản \u0026ldquo;Lộ IAM Key\u0026rdquo; đã làm nổi bật tầm quan trọng của tốc độ và tự động hóa trong việc phản ứng với sự cố. Kết nối và thảo luận Thảo luận về những thách thức khi triển khai Zero Trust trong các kiến trúc ứng dụng cũ (legacy). Trao đổi mẹo để chuẩn bị cho kỳ thi AWS Certified Security – Specialty. Bài học rút ra Ghi log mọi thứ: Bạn không thể phát hiện những gì bạn không ghi lại. VPC Flow Logs và CloudTrail là thiết yếu cho việc điều tra số (forensics). Tránh Key dài hạn: Các IAM access keys tĩnh là rủi ro lớn; chuyển sang dùng IAM Roles cho EC2/Lambda là ưu tiên hàng đầu. Tự động hóa là Bảo mật: Các kiểm tra bảo mật thủ công khó mở rộng quy mô; tự động hóa sử dụng EventBridge và Lambda cho phép khắc phục theo thời gian thực. Ảnh sự kiện "
},
{
	"uri": "//localhost:1313/vi/4-events/4.4-event4/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Báo cáo Tổng hợp: “Agentic AI \u0026amp; Điều phối trên AWS” Mục tiêu Sự kiện Khám phá kiến trúc cấp cao của Agentic AI (AI đại lý) sử dụng Amazon Bedrock. Hiểu bước chuyển từ GenAI tiêu chuẩn sang các quy trình \u0026ldquo;Agentic\u0026rdquo; có khả năng thực thi tác vụ. Học các kỹ thuật điều phối (orchestration) nâng cao và tối ưu hóa ngữ cảnh (cấp độ L300). Khảo sát các case study thực tế về triển khai agent từ Diaflow và CloudThinker. Có trải nghiệm thực hành xây dựng agent thông qua các phiên code tương tác. Diễn giả Nguyen Gia Hung – Trưởng bộ phận Kiến trúc sư Giải pháp, AWS Kien Nguyen – Kiến trúc sư Giải pháp, AWS Viet Pham – Nhà sáng lập \u0026amp; CEO, Diaflow Thang Ton – Đồng sáng lập \u0026amp; COO, CloudThinker Henry Bui – Trưởng bộ phận Kỹ thuật, CloudThinker Kha Van – Lãnh đạo Cộng đồng Điểm nhấn Chính Cốt lõi AWS Bedrock Agent Nền tảng: Đi sâu vào kỹ thuật kiến trúc của Amazon Bedrock Agents. Khả năng: Vượt ra ngoài việc tạo văn bản đơn giản để hướng tới các agent có thể lập kế hoạch, suy luận và thực thi hành động qua các lệnh gọi API. Kiến trúc: Hiểu cách bộ định tuyến agent (router), nhóm hành động (action groups) và cơ sở tri thức (knowledge bases) tương tác để giải quyết các truy vấn phức tạp của người dùng. Triển khai Thực tế (Diaflow) Case Study: Bài trình bày của CEO Diaflow về việc xây dựng các quy trình agentic thực tế. Tự động hóa Quy trình: Minh họa cách chuỗi các bước AI liên kết với nhau để tạo thành một quy trình kinh doanh gắn kết. Thách thức: Thảo luận về những trở ngại khi chuyển từ nguyên mẫu (prototype) sang thực tế (production) trong môi trường startup. Điều phối Nâng cao (CloudThinker) Đi sâu Kỹ thuật L300: Tập trung vào các thách thức kỹ thuật của việc điều phối AI. Tối ưu hóa Ngữ cảnh: Các kỹ thuật quản lý cửa sổ ngữ cảnh (context window) hiệu quả trên Amazon Bedrock để giảm chi phí và cải thiện độ chính xác. Khung Điều phối: Cách CloudThinker cấu trúc sự tương tác giữa các mô hình và công cụ khác nhau để duy trì trạng thái và ý định. Workshop Thực hành CloudThinker Hack: Phiên code tương tác được hướng dẫn bởi các kỹ sư. Triển khai: Chuyển từ lý thuyết sang mã, thiết lập cấu trúc cơ bản của một agent và kết nối nó với các dịch vụ AWS. Bài học Chính (Key Takeaways) Tư duy Thiết kế Agents vs. Chatbots: Sự dịch chuyển từ truy xuất thông tin thụ động (Chatbots) sang thực thi tác vụ chủ động (Agents). Ngữ cảnh là Vua: Tối ưu hóa những gì đưa vào cửa sổ ngữ cảnh quan trọng ngang với chính mô hình; quá nhiều nhiễu sẽ làm giảm hiệu suất. Điều phối: Các agent thành công cần một lớp mạnh mẽ để quản lý logic ra quyết định và trạng thái. Kiến trúc Kỹ thuật Sử dụng Công cụ: Các Agent chỉ tốt ngang với các công cụ (APIs/Functions) mà bạn cấp quyền truy cập cho chúng. Quản lý Trạng thái: Xử lý các cuộc hội thoại nhiều lượt (multi-turn) đòi hỏi theo dõi trạng thái cẩn thận để đảm bảo agent ghi nhớ các ràng buộc trước đó. Tối ưu hóa: Các chiến lược ngữ cảnh nâng cao là cần thiết để xử lý các cuộc hội thoại dài mà không gặp giới hạn token hoặc vấn đề về độ trễ. Ứng dụng vào Công việc Thử nghiệm với Bedrock Agents: Bắt đầu xây dựng một agent đơn giản kết nối với backend dự án \u0026ldquo;Meal Plan\u0026rdquo; để trả lời truy vấn người dùng (ví dụ: \u0026ldquo;Tìm cho tôi công thức dưới 500 calo\u0026rdquo;). Tinh chỉnh Ngữ cảnh: Xem xét lại cách dữ liệu người dùng được truyền vào LLM; triển khai cắt tỉa ngữ cảnh (context pruning) để giữ cho các prompt hiệu quả. Tích hợp Quy trình: Khám phá việc sử dụng quy trình agentic để tự động hóa các tác vụ quản trị backend (ví dụ: phê duyệt nội dung người dùng hoặc xác minh hình ảnh). Trải nghiệm Sự kiện Sự kiện “Agentic AI \u0026amp; Orchestration trên AWS” là một hành trình toàn diện từ các khái niệm cấp cao đến chi tiết kỹ thuật L300. Nó làm nổi bật sự phát triển nhanh chóng của AI từ \u0026ldquo;suy nghĩ\u0026rdquo; sang \u0026ldquo;hành động\u0026rdquo;.\nHọc hỏi từ chuyên gia Phiên L300 của Henry Bui đặc biệt sâu sắc về Tối ưu hóa Ngữ cảnh, đưa ra các chiến lược cụ thể để cải thiện hiệu suất mô hình và giảm độ trễ. Hiểu rõ về hệ sinh thái Amazon Bedrock và cách nó đơn giản hóa sự phức tạp của việc xây dựng các agent tùy chỉnh. Tiếp cận kỹ thuật thực tế CloudThinker Hack: Workshop cung cấp phần thực hành rất cần thiết, cho phép nhìn thấy code đằng sau các khái niệm. Ví dụ thực tế: Việc nhìn thấy triển khai của Diaflow đã chứng minh rằng Agentic AI đã sẵn sàng cho các trường hợp sử dụng kinh doanh thực tế, không chỉ là nghiên cứu. Kết nối và thảo luận Kết nối với đội ngũ CloudThinker trong bữa trưa buffet để thảo luận về các thách thức cụ thể trong việc điều phối hệ thống đa agent (multi-agent). Thảo luận với đồng nghiệp về cách tích hợp các agent này vào kiến trúc Spring Boot và React hiện có. Bài học rút ra Action Groups trong Bedrock là chìa khóa để mở khóa giá trị thực; việc định nghĩa các lược đồ API (API schemas) rõ ràng cho agent là rất quan trọng. Điều phối rất phức tạp; sử dụng một framework hoặc dịch vụ được quản lý như Bedrock Agents được ưu tiên hơn là tự xây dựng logic định tuyến từ đầu. Tương lai của phát triển ứng dụng là định hướng Agent (Agent-driven), nơi giao diện người dùng (UI) thích ứng với ý định của người dùng thay vì buộc người dùng phải điều hướng các menu tĩnh. Ảnh sự kiện "
},
{
	"uri": "//localhost:1313/vi/2-proposal/2.1-createec2/2.1.3-createprivatesubnet/",
	"title": "Tạo Private subnet",
	"tags": [],
	"description": "",
	"content": "Tạo Private subnet Click Subnets. Click Create subnet. Tại trang Create subnet. Tại mục VPC ID click chọn Lab VPC. Tại mục Subnet name điền Lab Private Subnet. Tại mục Availability Zone chọn Availability zone đầu tiên. Tại mục IPv4 CIRD block điền 10.10.2.0/24. Kéo xuống cuối trang , click Create subnet. Bước tiếp theo chúng ta sẽ tạo các security group cần thiết cho bài lab.\n"
},
{
	"uri": "//localhost:1313/vi/4-events/",
	"title": "Sự kiện đã tham gia",
	"tags": [],
	"description": "",
	"content": "Trong kỳ thực tập của mình, em đã tham gia bốn sự kiện. Mỗi sự kiện đều là một trải nghiệm đáng nhớ, mang lại những kiến thức mới mẻ, thú vị và bổ ích, cùng với những món quà và những khoảnh khắc tuyệt vời.\nSự kiện 1 Tên sự kiện: AWS Cloud Mastery Series #1\nThời gian: 08:00, ngày 15 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, số 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 2 Tên sự kiện: AWS Cloud Mastery Series #2\nThời gian: 08:30, ngày 17 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, số 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 3 Tên sự kiện: AWS Cloud Mastery Series #3\nThời gian: 08:30, ngày 29 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, số 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 4 Tên sự kiện: Building Agentic AI \u0026amp; Context Optimization with Amazon Bedrock\nThời gian: 09:00, ngày 05 tháng 12 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, số 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\n"
},
{
	"uri": "//localhost:1313/vi/2-proposal/2.1-createec2/2.1.4-createsecgroup/",
	"title": "Tạo các security group",
	"tags": [],
	"description": "",
	"content": "Tạo các security group Trong bước này chúng ta sẽ tiến hành tạo các security group được sử dụng cho các instance của chúng ta. Các bạn có thể thấy, các securiy group này sẽ không cần phải mở các port truyền thống để ssh như port 22 hoặc remote desktop thông qua port 3389.\nTạo security group cho Linux instance nằm trong public subnet Truy cập giao diện quản trị dịch vụ VPC Click Security Group. Click Create security group. Tại mục Security group name, điền SG Public Linux Instance. Tại mục Description, điền SG Public Linux Instance. Tại mục VPC, click dấu X để chọn lại Lab VPC bạn đã tạo cho bài lab này. Giữ nguyên Outbound rule, kéo chuột xuống phía dưới. Click Create security group. Các bạn có thể thấy, security group chúng ta tạo sử dụng cho Linux public instance sẽ không cần phải mở các port truyền thống để ssh như port 22.\nTạo security group cho Windows instance nằm trong private subnet Sau khi tạo thành công security group cho Linux instance nằm trong public subnet, click vào link Security Groups để quay trở lại danh sách Security groups. Click Create security group.\nTại mục Security group name, điền SG Private Windows Instance.\nTại mục Description, điền SG Private Windows Instance. Tại mục VPC, click dấu X để chọn lại Lab VPC bạn đã tạo cho bài lab này. Kéo chuột xuống phía dưới. Thêm Outbound rule cho phép kết nối TCP 443 tới 10.10.0.0/16 ( CIDR của Lab VPC chúng ta đã tạo) Click Create security group. Đối với Instance trong private subnet, chúng ta sẽ kết nối tới endpoint của Session Manager qua kết nối đã được mã hóa TLS. vì thế chúng ta cần cho phép kết nối chiều ra từ instance của mình tới VPC CIDR thông qua port 443.\nTạo security group cho VPC Endpoint Trong bước này, chúng ta sẽ tạo security group cho VPC Endpoint của Session Manager. Sau khi tạo thành công security group cho Windows instance trong private subnet, click vào link Security Groups để quay trở lại danh sách Security groups. Click Create security group. Tại mục Security group name, điền SG VPC Endpoint. Tại mục Description, điền SG VPC Endpoint. Tại mục VPC, click dấu X để chọn lại Lab VPC bạn đã tạo cho bài lab này. Kéo chuột xuống phía dưới. Xóa Outbound rule. Thêm Inbound rule cho phép TCP 443 đến từ 10.10.0.0/16 ( CIDR của Lab VPC chúng ta đã tạo ). Click Create security group. Như vậy chúng ta đã tiến hành xong việc tạo các security group cần thiết cho các EC2 instance và VPC Endpoint.\n"
},
{
	"uri": "//localhost:1313/vi/2-proposal/2.1-createec2/2.1.5-createec2linux/",
	"title": "Tạo Public Linux EC2",
	"tags": [],
	"description": "",
	"content": " Truy cập giao diện quản trị dịch vụ EC2 Click Instances. Click Launch instances. Tại trang Step 1: Choose an Amazon Machine Image (AMI). Click Select để lựa chọn AMI Amazon Linux 2 AMI. Tại trang Step 2: Choose an Instance Type. Click chọn Instance type t2.micro. Click Next: Configure Instance Details. Tại trang Step 3: Configure Instance Details Tại mục Network chọn Lab VPC. Tại mục Subnet chọn Lab Public Subnet. Tại mục Auto-assign Public IP chọn Use subnet setting (Enable) Click Next: Add Storage. Click Next: Add Tags để chuyển sang bước kế tiếp. Click Next: Configure Security Group để chuyển sang bước kế tiếp. Tại trang Step 6: Configure Security Group. Chọn Select an existing security group. Chọn security group SG Public Linux Instance. Click Review and Launch. Hộp thoại cảnh báo hiện lên vì chúng ta không cấu hình tường lửa cho phép kết nối vào port 22, Click Continue để tiếp tục.\nTại trang Step 7: Review Instance Launch.\nClick Launch. Tại hộp thoại Select an existing key pair or create a new key pair. Click chọn Create a new key pair. Tại mục Key pair name điền LabKeypair. Click Download Key Pair và lưu xuống máy tính của bạn. Click Launch Instances để tạo máy chủ EC2. Click View Instances để quay lại danh mục EC2 instances.\nClick vào biểu tượng edit dưới cột Name.\nTại hộp thoại Edit Name điền Public Linux Instance. Click Save. Tiếp theo chúng ta sẽ thực hiện tương tự để tạo 1 EC2 Instance Windows chạy trong Private subnet.\n"
},
{
	"uri": "//localhost:1313/vi/5-portfwd/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "\rPort Forwarding là mốt cách thức hữu ích để chuyển hướng lưu lượng mạng từ 1 địa chỉ IP - Port này sang 1 địa chỉ IP - Port khác. Với Port Forwarding chúng ta có thể truy cập một EC2 instance nằm trong private subnet từ máy trạm của chúng ta.\nChúng ta sẽ cấu hình Port Forwarding cho kết nối RDP giữa máy của mình với Private Windows Instance nằm trong private subnet mà chúng ta đã tạo cho bài thực hành này.\nTạo IAM User có quyền kết nối SSM Truy cập vào giao diện quản trị dịch vụ IAM Click Users , sau đó click Add users. Tại trang Add user. Tại mục User name, điền Portfwd. Click chọn Access key - Programmatic access. Click Next: Permissions. Click Attach existing policies directly. Tại ô tìm kiếm , điền ssm. Click chọn AmazonSSMFullAccess. Click Next: Tags, click Next: Reviews. Click Create user. Lưu lại thông tin Access key ID và Secret access key để thực hiện cấu hình AWS CLI. Cài đặt và cấu hình AWS CLI và Session Manager Plugin Để thực hiện phần thực hành này, đảm bảo máy trạm của bạn đã cài AWS CLI và Session Manager Plugin\nBạn có thể tham khảo thêm bài thực hành về cài đặt và cấu hình AWS CLI tại đây.\nVới Windows thì khi giải nén thư mục cài đặt Session Manager Plugin bạn hãy chạy file install.bat với quyền Administrator để thực hiện cài đặt.\nThực hiện Portforwarding Chạy command dưới đây trong Command Prompt trên máy của bạn để cấu hình Port Forwarding. aws ssm start-session --target (your ID windows instance) --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region (your region) Thông tin Instance ID của Windows Private Instance có thể tìm được khi bạn xem chi tiết máy chủ EC2 Windows Private Instance.\nCâu lệnh ví dụ C:\\Windows\\system32\u0026gt;aws ssm start-session --target i-06343d7377486760c --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region ap-southeast-1 Nếu câu lệnh của bạn báo lỗi như dưới đây : SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found\nChứng tỏ bạn chưa cài Session Manager Plugin thành công. Bạn có thể cần khởi chạy lại Command Prompt sau khi cài Session Manager Plugin.\nKết nối tới Private Windows Instance bạn đã tạo bằng công cụ Remote Desktop trên máy trạm của bạn. Tại mục Computer: điền localhost:9999. Quay trở lại giao diện quản trị của dịch vụ System Manager - Session Manager. Click tab Session history. Chúng ta sẽ thấy các session logs với tên Document là AWS-StartPortForwardingSession. Chúc mừng bạn đã hoàn tất bài thực hành hướng dẫn cách sử dụng Session Manager để kết nối cũng như lưu trữ các session logs trong S3 bucket. Hãy nhớ thực hiện bước dọn dẹp tài nguyên để tránh sinh chi phí ngoài ý muốn nhé.\n"
},
{
	"uri": "//localhost:1313/vi/2-proposal/2.1-createec2/2.1.6-createec2windows/",
	"title": "Tạo Private Windows EC2",
	"tags": [],
	"description": "",
	"content": " Truy cập giao diện quản trị dịch vụ EC2 Click Instances. Click Launch instances. Tại trang Step 1: Choose an Amazon Machine Image (AMI). Kéo chuột xuống phía dưới. Click Select để lựa chọn AMI Microsoft Windows Server 2019 Base. Tại trang Step 2: Choose an Instance Type. Click chọn Instance type t2.micro. Click Next: Configure Instance Details. Tại trang Step 3: Configure Instance Details Tại mục Network chọn Lab VPC. Tại mục Subnet chọn Lab Private Subnet. Tại mục Auto-assign Public IP chọn Use subnet setting (Disable) Click Next: Add Storage. Click Next: Add Tags để chuyển sang bước kế tiếp. Click Next: Configure Security Group để chuyển sang bước kế tiếp. Tại trang Step 6: Configure Security Group. Chọn Select an existing security group. Chọn security group SG Private Windows Instance. Click Review and Launch. Hộp thoại cảnh báo hiện lên vì chúng ta không cấu hình tường lửa cho phép kết nối vào port 22, Click Continue để tiếp tục.\nTại trang Step 7: Review Instance Launch.\nClick Launch. Tại hộp thoại Select an existing key pair or create a new key pair. Click chọn Choose an existing key pair. Tại mục Key pair name chọn LabKeypair. Click chọn I acknowledge that I have access to the corresponding private key file, and that without this file, I won\u0026rsquo;t be able to log into my instance.. Click Launch Instances để tạo máy chủ EC2. Click View Instances để quay lại danh mục EC2 instances.\nClick vào biểu tượng edit dưới cột Name.\nTại hộp thoại Edit Name điền Private Windows Instance. Click Save. Tiếp theo chúng ta sẽ tiến hành tạo các IAM Role để phục vụ cho Session Manager.\n"
},
{
	"uri": "//localhost:1313/vi/6-self-assessment/",
	"title": "Tự đánh giá bản thân",
	"tags": [],
	"description": "",
	"content": "Trong thời gian thực tập tại AWS First Cloud Journey từ 08/09/2025 đến 28/12/2025, tôi đã có cơ hội áp dụng những kiến thức đã học vào các nhiệm vụ phát triển thực tế và tích lũy kinh nghiệm trong môi trường làm việc chuyên nghiệp. Tôi tham gia vào việc xây dựng ứng dụng lập kế hoạch bữa ăn (meal-planning application), một hệ thống hỗ trợ người dùng muốn nấu ăn nhưng không có thời gian mua nguyên liệu. Thông qua dự án này, tôi đã mở rộng kỹ năng kỹ thuật với Spring Framework, PostgreSQL, AWS, đồng thời cải thiện khả năng giải quyết vấn đề, làm việc nhóm và tư duy thiết kế phần mềm.\nTrong suốt kỳ thực tập, tôi luôn giữ thái độ làm việc nghiêm túc, tuân thủ quy trình của công ty và thường xuyên trao đổi với các thành viên trong nhóm để đảm bảo tiến độ và chất lượng công việc.\nDưới đây là bảng tự đánh giá dựa trên các tiêu chí chính trong quá trình thực tập:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Năng lực kỹ thuật Hiểu kiến thức nền tảng, áp dụng vào thực tế, sử dụng công cụ hiệu quả [ ] ✅ [ ] 2 Khả năng học hỏi Tiếp thu kiến thức mới và thích ứng nhanh với nhiệm vụ mới [ ] ✅ [ ] 3 Tính chủ động Chủ động nhận việc, đề xuất ý tưởng, không chờ chỉ dẫn [ ] ✅ [ ] 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn và đảm bảo chất lượng ✅ [ ] [ ] 5 Kỷ luật làm việc Tuân thủ nội quy, thời gian và quy trình làm việc ✅ [ ] [ ] 6 Tinh thần cầu tiến Sẵn sàng nhận phản hồi và nỗ lực cải thiện bản thân ✅ [ ] [ ] 7 Khả năng giao tiếp Trình bày ý tưởng rõ ràng và báo cáo công việc hiệu quả [ ] [ ] ✅ 8 Kỹ năng làm việc nhóm Phối hợp với đồng đội và đóng góp tích cực trong các hoạt động nhóm [ ] [ ] ✅ 9 Tác phong chuyên nghiệp Tôn trọng đồng nghiệp, đối tác và môi trường làm việc ✅ [ ] [ ] 10 Tư duy phân tích \u0026amp; giải quyết vấn đề Xác định vấn đề, phân tích nguyên nhân và đề xuất giải pháp hiệu quả [ ] ✅ [ ] 11 Mức độ đóng góp dự án/nhóm Hiệu quả công việc, đóng góp ý tưởng và mức độ tham gia [ ] ✅ [ ] 12 Đánh giá tổng quan Nhận xét chung về toàn bộ quá trình thực tập [ ] ✅ [ ] Những điểm cần cải thiện Dựa trên bảng tự đánh giá, tôi xác định một số lĩnh vực cần tiếp tục hoàn thiện:\nNăng lực kỹ thuật: Dù đã nắm vững kiến thức cơ bản, tôi cần nâng cao khả năng sử dụng một số công cụ và đào sâu hơn về phát triển backend. Khả năng học hỏi: Tôi muốn cải thiện tốc độ tiếp thu công nghệ mới và cách áp dụng chúng một cách hiệu quả hơn. Tính chủ động: Tôi sẽ cố gắng chủ động hơn trong việc đề xuất ý tưởng và nhận nhiệm vụ trong quá trình phát triển dự án. Khả năng giao tiếp: Tôi cần rèn luyện khả năng diễn đạt rõ ràng, đặc biệt khi giải thích vấn đề kỹ thuật hoặc báo cáo tiến độ. Làm việc nhóm: Tôi muốn tham gia tích cực hơn trong các cuộc thảo luận nhóm và hỗ trợ đồng đội ổn định hơn. Giải quyết vấn đề: Tôi cần nâng cao khả năng nhận diện vấn đề sớm và đưa ra giải pháp có tính logic và hiệu quả. Hiệu suất tổng thể: Mặc dù đạt mức khá, tôi nhận thấy mình còn có thể cải thiện tính nhất quán, sự tự tin và kỹ năng kỹ thuật trong các nhiệm vụ được giao. Những mục tiêu cải thiện này sẽ giúp tôi làm việc hiệu quả hơn trong các dự án tương lai và tiếp tục phát triển bản thân trên con đường trở thành một kỹ sư phần mềm chuyên nghiệp.\n"
},
{
	"uri": "//localhost:1313/vi/7-sharing-and-feedback/",
	"title": "Chia sẻ và Phản hồi ",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]